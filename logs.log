2022-11-22 15:43:27,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 15:43:27,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 15:43:27,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 15:43:27,662:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 15:43:41,377:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-11-22 15:44:28,305:INFO:PyCaret ClassificationExperiment
2022-11-22 15:44:28,306:INFO:Logging name: clf-default-name
2022-11-22 15:44:28,306:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-11-22 15:44:28,306:INFO:version 3.0.0.rc4
2022-11-22 15:44:28,307:INFO:Initializing setup()
2022-11-22 15:44:28,307:INFO:self.USI: 3bfa
2022-11-22 15:44:28,307:INFO:self.variable_keys: {'idx', 'master_model_container', 'memory', 'exp_name_log', 'logging_param', 'USI', 'X', '_is_multiclass', 'fix_imbalance', '_all_models_internal', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'fold_generator', '_gpu_n_jobs_param', 'html_param', 'log_plots_param', '_all_models', 'X_train', 'seed', 'y_test', 'gpu_param', 'n_jobs_param', '_all_metrics', 'data', 'fold_shuffle_param', 'pipeline', 'target_param', 'display_container', 'exp_id', '_ml_usecase', 'X_test', 'variable_keys'}
2022-11-22 15:44:28,307:INFO:Checking environment
2022-11-22 15:44:28,307:INFO:python_version: 3.10.7
2022-11-22 15:44:28,308:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-11-22 15:44:28,308:INFO:machine: AMD64
2022-11-22 15:44:28,308:INFO:platform: Windows-10-10.0.19044-SP0
2022-11-22 15:44:28,308:INFO:Memory: svmem(total=8017076224, available=2219978752, percent=72.3, used=5797097472, free=2219978752)
2022-11-22 15:44:28,309:INFO:Physical Core: 2
2022-11-22 15:44:28,309:INFO:Logical Core: 2
2022-11-22 15:44:28,309:INFO:Checking libraries
2022-11-22 15:44:28,309:INFO:System:
2022-11-22 15:44:28,309:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-11-22 15:44:28,310:INFO:executable: c:\Users\nacho\ignacio-boot\venv_analitycs\Scripts\python.exe
2022-11-22 15:44:28,310:INFO:   machine: Windows-10-10.0.19044-SP0
2022-11-22 15:44:28,310:INFO:PyCaret required dependencies:
2022-11-22 15:44:28,310:INFO:                 pip: 22.3.1
2022-11-22 15:44:28,314:INFO:          setuptools: 63.2.0
2022-11-22 15:44:28,314:INFO:             pycaret: 3.0.0rc4
2022-11-22 15:44:28,315:INFO:             IPython: 8.5.0
2022-11-22 15:44:28,315:INFO:          ipywidgets: 8.0.2
2022-11-22 15:44:28,315:INFO:                tqdm: 4.64.1
2022-11-22 15:44:28,315:INFO:               numpy: 1.22.4
2022-11-22 15:44:28,318:INFO:              pandas: 1.4.4
2022-11-22 15:44:28,318:INFO:              jinja2: 3.1.2
2022-11-22 15:44:28,319:INFO:               scipy: 1.8.1
2022-11-22 15:44:28,319:INFO:              joblib: 1.2.0
2022-11-22 15:44:28,319:INFO:             sklearn: 1.1.2
2022-11-22 15:44:28,319:INFO:                pyod: 1.0.6
2022-11-22 15:44:28,319:INFO:            imblearn: 0.9.1
2022-11-22 15:44:28,319:INFO:   category_encoders: 2.5.1.post0
2022-11-22 15:44:28,320:INFO:            lightgbm: 3.3.3
2022-11-22 15:44:28,320:INFO:               numba: 0.55.2
2022-11-22 15:44:28,320:INFO:            requests: 2.28.1
2022-11-22 15:44:28,320:INFO:          matplotlib: 3.6.0
2022-11-22 15:44:28,320:INFO:          scikitplot: 0.3.7
2022-11-22 15:44:28,322:INFO:         yellowbrick: 1.5
2022-11-22 15:44:28,322:INFO:              plotly: 5.10.0
2022-11-22 15:44:28,323:INFO:             kaleido: 0.2.1
2022-11-22 15:44:28,324:INFO:         statsmodels: 0.13.2
2022-11-22 15:44:28,324:INFO:              sktime: 0.13.4
2022-11-22 15:44:28,324:INFO:               tbats: 1.1.1
2022-11-22 15:44:28,324:INFO:            pmdarima: 1.8.5
2022-11-22 15:44:28,325:INFO:              psutil: 5.9.2
2022-11-22 15:44:28,325:INFO:PyCaret optional dependencies:
2022-11-22 15:44:28,707:INFO:                shap: Not installed
2022-11-22 15:44:28,708:INFO:           interpret: Not installed
2022-11-22 15:44:28,708:INFO:                umap: Not installed
2022-11-22 15:44:28,708:INFO:    pandas_profiling: Not installed
2022-11-22 15:44:28,708:INFO:  explainerdashboard: Not installed
2022-11-22 15:44:28,709:INFO:             autoviz: Not installed
2022-11-22 15:44:28,709:INFO:           fairlearn: Not installed
2022-11-22 15:44:28,709:INFO:             xgboost: 1.7.1
2022-11-22 15:44:28,709:INFO:            catboost: Not installed
2022-11-22 15:44:28,710:INFO:              kmodes: Not installed
2022-11-22 15:44:28,711:INFO:             mlxtend: Not installed
2022-11-22 15:44:28,711:INFO:       statsforecast: Not installed
2022-11-22 15:44:28,711:INFO:        tune_sklearn: Not installed
2022-11-22 15:44:28,711:INFO:                 ray: Not installed
2022-11-22 15:44:28,712:INFO:            hyperopt: Not installed
2022-11-22 15:44:28,712:INFO:              optuna: 3.0.3
2022-11-22 15:44:28,712:INFO:               skopt: 0.9.0
2022-11-22 15:44:28,712:INFO:              mlflow: Not installed
2022-11-22 15:44:28,712:INFO:              gradio: Not installed
2022-11-22 15:44:28,712:INFO:             fastapi: Not installed
2022-11-22 15:44:28,829:INFO:             uvicorn: Not installed
2022-11-22 15:44:28,829:INFO:              m2cgen: Not installed
2022-11-22 15:44:28,829:INFO:           evidently: Not installed
2022-11-22 15:44:28,829:INFO:                nltk: Not installed
2022-11-22 15:44:28,830:INFO:            pyLDAvis: Not installed
2022-11-22 15:44:28,831:INFO:              gensim: Not installed
2022-11-22 15:44:28,831:INFO:               spacy: Not installed
2022-11-22 15:44:28,832:INFO:           wordcloud: 1.8.2.2
2022-11-22 15:44:28,832:INFO:            textblob: Not installed
2022-11-22 15:44:28,836:INFO:               fugue: Not installed
2022-11-22 15:44:28,837:INFO:           streamlit: 1.15.0
2022-11-22 15:44:28,837:INFO:             prophet: Not installed
2022-11-22 15:44:28,837:INFO:None
2022-11-22 15:44:28,837:INFO:Set up data.
2022-11-22 15:44:28,993:INFO:Set up train/test split.
2022-11-22 15:45:56,818:INFO:PyCaret ClassificationExperiment
2022-11-22 15:45:56,818:INFO:Logging name: clf-default-name
2022-11-22 15:45:56,819:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-11-22 15:45:56,819:INFO:version 3.0.0.rc4
2022-11-22 15:45:56,819:INFO:Initializing setup()
2022-11-22 15:45:56,819:INFO:self.USI: a496
2022-11-22 15:45:56,819:INFO:self.variable_keys: {'idx', 'master_model_container', 'memory', 'exp_name_log', 'logging_param', 'USI', 'X', '_is_multiclass', 'fix_imbalance', '_all_models_internal', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'fold_generator', '_gpu_n_jobs_param', 'html_param', 'log_plots_param', '_all_models', 'X_train', 'seed', 'y_test', 'gpu_param', 'n_jobs_param', '_all_metrics', 'data', 'fold_shuffle_param', 'pipeline', 'target_param', 'display_container', 'exp_id', '_ml_usecase', 'X_test', 'variable_keys'}
2022-11-22 15:45:56,822:INFO:Checking environment
2022-11-22 15:45:56,822:INFO:python_version: 3.10.7
2022-11-22 15:45:56,822:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-11-22 15:45:56,823:INFO:machine: AMD64
2022-11-22 15:45:56,823:INFO:platform: Windows-10-10.0.19044-SP0
2022-11-22 15:45:56,823:INFO:Memory: svmem(total=8017076224, available=2062991360, percent=74.3, used=5954084864, free=2062991360)
2022-11-22 15:45:56,824:INFO:Physical Core: 2
2022-11-22 15:45:56,824:INFO:Logical Core: 2
2022-11-22 15:45:56,824:INFO:Checking libraries
2022-11-22 15:45:56,826:INFO:System:
2022-11-22 15:45:56,827:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-11-22 15:45:56,828:INFO:executable: c:\Users\nacho\ignacio-boot\venv_analitycs\Scripts\python.exe
2022-11-22 15:45:56,828:INFO:   machine: Windows-10-10.0.19044-SP0
2022-11-22 15:45:56,829:INFO:PyCaret required dependencies:
2022-11-22 15:45:56,829:INFO:                 pip: 22.3.1
2022-11-22 15:45:56,836:INFO:          setuptools: 63.2.0
2022-11-22 15:45:56,837:INFO:             pycaret: 3.0.0rc4
2022-11-22 15:45:56,837:INFO:             IPython: 8.5.0
2022-11-22 15:45:56,837:INFO:          ipywidgets: 8.0.2
2022-11-22 15:45:56,838:INFO:                tqdm: 4.64.1
2022-11-22 15:45:56,838:INFO:               numpy: 1.22.4
2022-11-22 15:45:56,838:INFO:              pandas: 1.4.4
2022-11-22 15:45:56,839:INFO:              jinja2: 3.1.2
2022-11-22 15:45:56,842:INFO:               scipy: 1.8.1
2022-11-22 15:45:56,842:INFO:              joblib: 1.2.0
2022-11-22 15:45:56,843:INFO:             sklearn: 1.1.2
2022-11-22 15:45:56,843:INFO:                pyod: 1.0.6
2022-11-22 15:45:56,843:INFO:            imblearn: 0.9.1
2022-11-22 15:45:56,843:INFO:   category_encoders: 2.5.1.post0
2022-11-22 15:45:56,844:INFO:            lightgbm: 3.3.3
2022-11-22 15:45:56,847:INFO:               numba: 0.55.2
2022-11-22 15:45:56,847:INFO:            requests: 2.28.1
2022-11-22 15:45:56,847:INFO:          matplotlib: 3.6.0
2022-11-22 15:45:56,848:INFO:          scikitplot: 0.3.7
2022-11-22 15:45:56,848:INFO:         yellowbrick: 1.5
2022-11-22 15:45:56,848:INFO:              plotly: 5.10.0
2022-11-22 15:45:56,848:INFO:             kaleido: 0.2.1
2022-11-22 15:45:56,848:INFO:         statsmodels: 0.13.2
2022-11-22 15:45:56,848:INFO:              sktime: 0.13.4
2022-11-22 15:45:56,849:INFO:               tbats: 1.1.1
2022-11-22 15:45:56,849:INFO:            pmdarima: 1.8.5
2022-11-22 15:45:56,849:INFO:              psutil: 5.9.2
2022-11-22 15:45:56,849:INFO:PyCaret optional dependencies:
2022-11-22 15:45:56,851:INFO:                shap: Not installed
2022-11-22 15:45:56,851:INFO:           interpret: Not installed
2022-11-22 15:45:56,851:INFO:                umap: Not installed
2022-11-22 15:45:56,851:INFO:    pandas_profiling: Not installed
2022-11-22 15:45:56,851:INFO:  explainerdashboard: Not installed
2022-11-22 15:45:56,852:INFO:             autoviz: Not installed
2022-11-22 15:45:56,852:INFO:           fairlearn: Not installed
2022-11-22 15:45:56,852:INFO:             xgboost: 1.7.1
2022-11-22 15:45:56,852:INFO:            catboost: Not installed
2022-11-22 15:45:56,852:INFO:              kmodes: Not installed
2022-11-22 15:45:56,853:INFO:             mlxtend: Not installed
2022-11-22 15:45:56,853:INFO:       statsforecast: Not installed
2022-11-22 15:45:56,853:INFO:        tune_sklearn: Not installed
2022-11-22 15:45:56,853:INFO:                 ray: Not installed
2022-11-22 15:45:56,853:INFO:            hyperopt: Not installed
2022-11-22 15:45:56,853:INFO:              optuna: 3.0.3
2022-11-22 15:45:56,853:INFO:               skopt: 0.9.0
2022-11-22 15:45:56,854:INFO:              mlflow: Not installed
2022-11-22 15:45:56,854:INFO:              gradio: Not installed
2022-11-22 15:45:56,854:INFO:             fastapi: Not installed
2022-11-22 15:45:56,854:INFO:             uvicorn: Not installed
2022-11-22 15:45:56,854:INFO:              m2cgen: Not installed
2022-11-22 15:45:56,855:INFO:           evidently: Not installed
2022-11-22 15:45:56,855:INFO:                nltk: Not installed
2022-11-22 15:45:56,855:INFO:            pyLDAvis: Not installed
2022-11-22 15:45:56,855:INFO:              gensim: Not installed
2022-11-22 15:45:56,855:INFO:               spacy: Not installed
2022-11-22 15:45:56,855:INFO:           wordcloud: 1.8.2.2
2022-11-22 15:45:56,856:INFO:            textblob: Not installed
2022-11-22 15:45:56,856:INFO:               fugue: Not installed
2022-11-22 15:45:56,856:INFO:           streamlit: 1.15.0
2022-11-22 15:45:56,856:INFO:             prophet: Not installed
2022-11-22 15:45:56,856:INFO:None
2022-11-22 15:45:56,856:INFO:Set up data.
2022-11-22 15:45:57,106:INFO:Set up train/test split.
2022-11-22 15:48:21,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 15:48:21,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 15:48:21,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 15:48:21,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 15:48:31,427:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-11-22 15:48:33,614:INFO:PyCaret RegressionExperiment
2022-11-22 15:48:33,615:INFO:Logging name: reg-default-name
2022-11-22 15:48:33,615:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-22 15:48:33,615:INFO:version 3.0.0.rc4
2022-11-22 15:48:33,615:INFO:Initializing setup()
2022-11-22 15:48:33,616:INFO:self.USI: 2ed7
2022-11-22 15:48:33,616:INFO:self.variable_keys: {'seed', 'data', 'fold_generator', 'logging_param', 'exp_id', 'memory', 'target_param', 'y', '_all_metrics', 'idx', 'exp_name_log', 'n_jobs_param', '_ml_usecase', 'X', 'X_train', 'html_param', 'pipeline', 'variable_keys', 'fold_groups_param', '_gpu_n_jobs_param', 'display_container', 'y_test', 'gpu_param', 'USI', 'transform_target_param', 'transform_target_method_param', 'master_model_container', 'X_test', '_all_models_internal', '_all_models', 'fold_shuffle_param', 'y_train', '_available_plots', 'log_plots_param'}
2022-11-22 15:48:33,616:INFO:Checking environment
2022-11-22 15:48:33,616:INFO:python_version: 3.10.7
2022-11-22 15:48:33,616:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-11-22 15:48:33,616:INFO:machine: AMD64
2022-11-22 15:48:33,617:INFO:platform: Windows-10-10.0.19044-SP0
2022-11-22 15:48:33,617:INFO:Memory: svmem(total=8017076224, available=2081153024, percent=74.0, used=5935923200, free=2081153024)
2022-11-22 15:48:33,617:INFO:Physical Core: 2
2022-11-22 15:48:33,617:INFO:Logical Core: 2
2022-11-22 15:48:33,617:INFO:Checking libraries
2022-11-22 15:48:33,618:INFO:System:
2022-11-22 15:48:33,618:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-11-22 15:48:33,618:INFO:executable: c:\Users\nacho\ignacio-boot\venv_analitycs\Scripts\python.exe
2022-11-22 15:48:33,618:INFO:   machine: Windows-10-10.0.19044-SP0
2022-11-22 15:48:33,618:INFO:PyCaret required dependencies:
2022-11-22 15:48:33,618:INFO:                 pip: 22.3.1
2022-11-22 15:48:33,619:INFO:          setuptools: 63.2.0
2022-11-22 15:48:33,619:INFO:             pycaret: 3.0.0rc4
2022-11-22 15:48:33,624:INFO:             IPython: 8.5.0
2022-11-22 15:48:33,625:INFO:          ipywidgets: 8.0.2
2022-11-22 15:48:33,625:INFO:                tqdm: 4.64.1
2022-11-22 15:48:33,625:INFO:               numpy: 1.22.4
2022-11-22 15:48:33,626:INFO:              pandas: 1.4.4
2022-11-22 15:48:33,626:INFO:              jinja2: 3.1.2
2022-11-22 15:48:33,626:INFO:               scipy: 1.8.1
2022-11-22 15:48:33,626:INFO:              joblib: 1.2.0
2022-11-22 15:48:33,626:INFO:             sklearn: 1.1.2
2022-11-22 15:48:33,627:INFO:                pyod: 1.0.6
2022-11-22 15:48:33,627:INFO:            imblearn: 0.9.1
2022-11-22 15:48:33,627:INFO:   category_encoders: 2.5.1.post0
2022-11-22 15:48:33,627:INFO:            lightgbm: 3.3.3
2022-11-22 15:48:33,627:INFO:               numba: 0.55.2
2022-11-22 15:48:33,628:INFO:            requests: 2.28.1
2022-11-22 15:48:33,628:INFO:          matplotlib: 3.6.0
2022-11-22 15:48:33,629:INFO:          scikitplot: 0.3.7
2022-11-22 15:48:33,629:INFO:         yellowbrick: 1.5
2022-11-22 15:48:33,629:INFO:              plotly: 5.10.0
2022-11-22 15:48:33,629:INFO:             kaleido: 0.2.1
2022-11-22 15:48:33,629:INFO:         statsmodels: 0.13.2
2022-11-22 15:48:33,629:INFO:              sktime: 0.13.4
2022-11-22 15:48:33,630:INFO:               tbats: 1.1.1
2022-11-22 15:48:33,630:INFO:            pmdarima: 1.8.5
2022-11-22 15:48:33,630:INFO:              psutil: 5.9.2
2022-11-22 15:48:33,631:INFO:PyCaret optional dependencies:
2022-11-22 15:48:33,918:INFO:                shap: Not installed
2022-11-22 15:48:33,918:INFO:           interpret: Not installed
2022-11-22 15:48:33,918:INFO:                umap: Not installed
2022-11-22 15:48:33,918:INFO:    pandas_profiling: Not installed
2022-11-22 15:48:33,919:INFO:  explainerdashboard: Not installed
2022-11-22 15:48:33,919:INFO:             autoviz: Not installed
2022-11-22 15:48:33,926:INFO:           fairlearn: Not installed
2022-11-22 15:48:33,927:INFO:             xgboost: 1.7.1
2022-11-22 15:48:33,927:INFO:            catboost: Not installed
2022-11-22 15:48:33,927:INFO:              kmodes: Not installed
2022-11-22 15:48:33,927:INFO:             mlxtend: Not installed
2022-11-22 15:48:33,927:INFO:       statsforecast: Not installed
2022-11-22 15:48:33,928:INFO:        tune_sklearn: Not installed
2022-11-22 15:48:33,928:INFO:                 ray: Not installed
2022-11-22 15:48:33,928:INFO:            hyperopt: Not installed
2022-11-22 15:48:33,929:INFO:              optuna: 3.0.3
2022-11-22 15:48:33,929:INFO:               skopt: 0.9.0
2022-11-22 15:48:33,929:INFO:              mlflow: Not installed
2022-11-22 15:48:33,932:INFO:              gradio: Not installed
2022-11-22 15:48:33,934:INFO:             fastapi: Not installed
2022-11-22 15:48:33,934:INFO:             uvicorn: Not installed
2022-11-22 15:48:33,935:INFO:              m2cgen: Not installed
2022-11-22 15:48:33,935:INFO:           evidently: Not installed
2022-11-22 15:48:33,935:INFO:                nltk: Not installed
2022-11-22 15:48:33,935:INFO:            pyLDAvis: Not installed
2022-11-22 15:48:33,935:INFO:              gensim: Not installed
2022-11-22 15:48:33,935:INFO:               spacy: Not installed
2022-11-22 15:48:33,937:INFO:           wordcloud: 1.8.2.2
2022-11-22 15:48:33,938:INFO:            textblob: Not installed
2022-11-22 15:48:33,938:INFO:               fugue: Not installed
2022-11-22 15:48:33,938:INFO:           streamlit: 1.15.0
2022-11-22 15:48:33,939:INFO:             prophet: Not installed
2022-11-22 15:48:33,939:INFO:None
2022-11-22 15:48:33,943:INFO:Set up data.
2022-11-22 15:48:34,028:INFO:Set up train/test split.
2022-11-22 15:48:34,249:INFO:Set up index.
2022-11-22 15:48:34,251:INFO:Set up folding strategy.
2022-11-22 15:48:34,251:INFO:Assigning column types.
2022-11-22 15:48:34,291:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-22 15:48:34,294:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-22 15:48:34,464:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 15:48:34,493:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 15:48:35,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 15:48:36,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 15:48:36,113:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:39,456:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:39,457:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-22 15:48:39,494:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 15:48:39,540:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 15:48:40,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 15:48:40,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 15:48:40,247:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:40,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:40,261:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-22 15:48:40,292:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 15:48:40,312:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 15:48:40,639:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 15:48:40,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 15:48:40,887:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:40,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:40,917:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 15:48:40,947:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 15:48:41,257:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 15:48:41,484:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 15:48:41,490:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:41,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:41,498:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-22 15:48:41,556:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 15:48:42,016:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 15:48:42,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 15:48:42,259:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:42,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:42,318:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 15:48:42,632:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 15:48:42,888:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 15:48:42,892:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:42,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:42,900:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-22 15:48:43,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 15:48:43,466:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 15:48:43,472:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:43,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:43,880:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 15:48:44,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 15:48:44,113:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:44,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:44,129:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-22 15:48:44,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 15:48:44,615:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:44,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:44,895:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 15:48:45,057:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:45,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:45,067:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-22 15:48:45,459:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:45,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:45,899:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:45,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:45,918:INFO:Preparing preprocessing pipeline...
2022-11-22 15:48:45,927:INFO:Set up simple imputation.
2022-11-22 15:48:45,927:INFO:Set up variance threshold.
2022-11-22 15:48:46,307:INFO:Finished creating preprocessing pipeline.
2022-11-22 15:48:46,331:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\nacho\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-22 15:48:46,332:INFO:Creating final display dataframe.
2022-11-22 15:48:47,914:INFO:Setup display_container:                Description             Value
0               Session id              6230
1                   Target             price
2              Target type        Regression
3               Data shape        (5000, 13)
4         Train data shape        (3499, 13)
5          Test data shape        (1501, 13)
6         Numeric features                12
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              2ed7
2022-11-22 15:48:48,943:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:48,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:50,623:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-22 15:48:50,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 15:48:50,678:INFO:setup() successfully completed in 17.07s...............
2022-11-22 15:48:51,012:INFO:Initializing compare_models()
2022-11-22 15:48:51,013:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-22 15:48:51,013:INFO:Checking exceptions
2022-11-22 15:48:51,022:INFO:Preparing display monitor
2022-11-22 15:48:51,412:INFO:Initializing Linear Regression
2022-11-22 15:48:51,412:INFO:Total runtime is 1.672506332397461e-05 minutes
2022-11-22 15:48:51,474:INFO:SubProcess create_model() called ==================================
2022-11-22 15:48:51,475:INFO:Initializing create_model()
2022-11-22 15:48:51,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:48:51,476:INFO:Checking exceptions
2022-11-22 15:48:51,487:INFO:Importing libraries
2022-11-22 15:48:51,488:INFO:Copying training dataset
2022-11-22 15:48:51,507:INFO:Defining folds
2022-11-22 15:48:51,508:INFO:Declaring metric variables
2022-11-22 15:48:51,596:INFO:Importing untrained model
2022-11-22 15:48:51,617:INFO:Linear Regression Imported successfully
2022-11-22 15:48:51,677:INFO:Starting cross validation
2022-11-22 15:48:51,799:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:49:20,812:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-11-22 15:49:21,965:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-11-22 15:49:30,787:INFO:Calculating mean and std
2022-11-22 15:49:30,798:INFO:Creating metrics dataframe
2022-11-22 15:49:30,832:INFO:Uploading results into container
2022-11-22 15:49:30,837:INFO:Uploading model into container now
2022-11-22 15:49:30,838:INFO:master_model_container: 1
2022-11-22 15:49:30,839:INFO:display_container: 2
2022-11-22 15:49:30,839:INFO:LinearRegression(n_jobs=-1)
2022-11-22 15:49:30,839:INFO:create_model() successfully completed......................................
2022-11-22 15:49:31,478:INFO:SubProcess create_model() end ==================================
2022-11-22 15:49:31,479:INFO:Creating metrics dataframe
2022-11-22 15:49:31,527:INFO:Initializing Lasso Regression
2022-11-22 15:49:31,527:INFO:Total runtime is 0.6685999155044555 minutes
2022-11-22 15:49:31,564:INFO:SubProcess create_model() called ==================================
2022-11-22 15:49:31,568:INFO:Initializing create_model()
2022-11-22 15:49:31,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:49:31,569:INFO:Checking exceptions
2022-11-22 15:49:31,576:INFO:Importing libraries
2022-11-22 15:49:31,577:INFO:Copying training dataset
2022-11-22 15:49:31,694:INFO:Defining folds
2022-11-22 15:49:31,694:INFO:Declaring metric variables
2022-11-22 15:49:31,724:INFO:Importing untrained model
2022-11-22 15:49:31,788:INFO:Lasso Regression Imported successfully
2022-11-22 15:49:31,877:INFO:Starting cross validation
2022-11-22 15:49:31,888:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:49:35,342:INFO:Calculating mean and std
2022-11-22 15:49:35,355:INFO:Creating metrics dataframe
2022-11-22 15:49:35,375:INFO:Uploading results into container
2022-11-22 15:49:35,377:INFO:Uploading model into container now
2022-11-22 15:49:35,379:INFO:master_model_container: 2
2022-11-22 15:49:35,380:INFO:display_container: 2
2022-11-22 15:49:35,386:INFO:Lasso(random_state=6230)
2022-11-22 15:49:35,387:INFO:create_model() successfully completed......................................
2022-11-22 15:49:35,942:INFO:SubProcess create_model() end ==================================
2022-11-22 15:49:35,942:INFO:Creating metrics dataframe
2022-11-22 15:49:35,991:INFO:Initializing Ridge Regression
2022-11-22 15:49:35,992:INFO:Total runtime is 0.743011995156606 minutes
2022-11-22 15:49:36,045:INFO:SubProcess create_model() called ==================================
2022-11-22 15:49:36,046:INFO:Initializing create_model()
2022-11-22 15:49:36,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:49:36,047:INFO:Checking exceptions
2022-11-22 15:49:36,057:INFO:Importing libraries
2022-11-22 15:49:36,057:INFO:Copying training dataset
2022-11-22 15:49:36,114:INFO:Defining folds
2022-11-22 15:49:36,114:INFO:Declaring metric variables
2022-11-22 15:49:36,190:INFO:Importing untrained model
2022-11-22 15:49:36,223:INFO:Ridge Regression Imported successfully
2022-11-22 15:49:36,328:INFO:Starting cross validation
2022-11-22 15:49:36,335:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:49:37,722:INFO:Calculating mean and std
2022-11-22 15:49:37,728:INFO:Creating metrics dataframe
2022-11-22 15:49:37,748:INFO:Uploading results into container
2022-11-22 15:49:37,754:INFO:Uploading model into container now
2022-11-22 15:49:37,755:INFO:master_model_container: 3
2022-11-22 15:49:37,755:INFO:display_container: 2
2022-11-22 15:49:37,756:INFO:Ridge(random_state=6230)
2022-11-22 15:49:37,757:INFO:create_model() successfully completed......................................
2022-11-22 15:49:38,914:INFO:SubProcess create_model() end ==================================
2022-11-22 15:49:38,914:INFO:Creating metrics dataframe
2022-11-22 15:49:38,967:INFO:Initializing Elastic Net
2022-11-22 15:49:38,967:INFO:Total runtime is 0.7925930023193359 minutes
2022-11-22 15:49:38,994:INFO:SubProcess create_model() called ==================================
2022-11-22 15:49:38,995:INFO:Initializing create_model()
2022-11-22 15:49:38,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:49:38,996:INFO:Checking exceptions
2022-11-22 15:49:39,013:INFO:Importing libraries
2022-11-22 15:49:39,013:INFO:Copying training dataset
2022-11-22 15:49:39,138:INFO:Defining folds
2022-11-22 15:49:39,138:INFO:Declaring metric variables
2022-11-22 15:49:39,178:INFO:Importing untrained model
2022-11-22 15:49:39,220:INFO:Elastic Net Imported successfully
2022-11-22 15:49:39,337:INFO:Starting cross validation
2022-11-22 15:49:39,340:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:49:41,437:INFO:Calculating mean and std
2022-11-22 15:49:41,454:INFO:Creating metrics dataframe
2022-11-22 15:49:41,473:INFO:Uploading results into container
2022-11-22 15:49:41,475:INFO:Uploading model into container now
2022-11-22 15:49:41,476:INFO:master_model_container: 4
2022-11-22 15:49:41,477:INFO:display_container: 2
2022-11-22 15:49:41,477:INFO:ElasticNet(random_state=6230)
2022-11-22 15:49:41,478:INFO:create_model() successfully completed......................................
2022-11-22 15:49:42,228:INFO:SubProcess create_model() end ==================================
2022-11-22 15:49:42,228:INFO:Creating metrics dataframe
2022-11-22 15:49:42,306:INFO:Initializing Least Angle Regression
2022-11-22 15:49:42,307:INFO:Total runtime is 0.848239254951477 minutes
2022-11-22 15:49:42,355:INFO:SubProcess create_model() called ==================================
2022-11-22 15:49:42,356:INFO:Initializing create_model()
2022-11-22 15:49:42,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:49:42,357:INFO:Checking exceptions
2022-11-22 15:49:42,447:INFO:Importing libraries
2022-11-22 15:49:42,451:INFO:Copying training dataset
2022-11-22 15:49:42,550:INFO:Defining folds
2022-11-22 15:49:42,551:INFO:Declaring metric variables
2022-11-22 15:49:42,611:INFO:Importing untrained model
2022-11-22 15:49:42,655:INFO:Least Angle Regression Imported successfully
2022-11-22 15:49:42,775:INFO:Starting cross validation
2022-11-22 15:49:42,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:49:43,165:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:43,179:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:43,514:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:43,627:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:43,860:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:43,939:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:44,426:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:44,559:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:44,912:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:45,013:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:45,102:INFO:Calculating mean and std
2022-11-22 15:49:45,109:INFO:Creating metrics dataframe
2022-11-22 15:49:45,123:INFO:Uploading results into container
2022-11-22 15:49:45,125:INFO:Uploading model into container now
2022-11-22 15:49:45,126:INFO:master_model_container: 5
2022-11-22 15:49:45,126:INFO:display_container: 2
2022-11-22 15:49:45,127:INFO:Lars(random_state=6230)
2022-11-22 15:49:45,127:INFO:create_model() successfully completed......................................
2022-11-22 15:49:45,696:INFO:SubProcess create_model() end ==================================
2022-11-22 15:49:45,696:INFO:Creating metrics dataframe
2022-11-22 15:49:45,757:INFO:Initializing Lasso Least Angle Regression
2022-11-22 15:49:45,757:INFO:Total runtime is 0.9057684302330017 minutes
2022-11-22 15:49:45,898:INFO:SubProcess create_model() called ==================================
2022-11-22 15:49:45,901:INFO:Initializing create_model()
2022-11-22 15:49:45,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:49:45,901:INFO:Checking exceptions
2022-11-22 15:49:45,911:INFO:Importing libraries
2022-11-22 15:49:45,911:INFO:Copying training dataset
2022-11-22 15:49:45,939:INFO:Defining folds
2022-11-22 15:49:45,940:INFO:Declaring metric variables
2022-11-22 15:49:45,956:INFO:Importing untrained model
2022-11-22 15:49:46,071:INFO:Lasso Least Angle Regression Imported successfully
2022-11-22 15:49:46,187:INFO:Starting cross validation
2022-11-22 15:49:46,189:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:49:46,350:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 15:49:46,453:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 15:49:46,709:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 15:49:46,809:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 15:49:46,927:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 15:49:47,117:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 15:49:47,206:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 15:49:47,469:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 15:49:47,654:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 15:49:47,764:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 15:49:47,853:INFO:Calculating mean and std
2022-11-22 15:49:47,859:INFO:Creating metrics dataframe
2022-11-22 15:49:47,905:INFO:Uploading results into container
2022-11-22 15:49:47,909:INFO:Uploading model into container now
2022-11-22 15:49:47,910:INFO:master_model_container: 6
2022-11-22 15:49:47,911:INFO:display_container: 2
2022-11-22 15:49:47,912:INFO:LassoLars(random_state=6230)
2022-11-22 15:49:47,912:INFO:create_model() successfully completed......................................
2022-11-22 15:49:48,719:INFO:SubProcess create_model() end ==================================
2022-11-22 15:49:48,720:INFO:Creating metrics dataframe
2022-11-22 15:49:48,893:INFO:Initializing Orthogonal Matching Pursuit
2022-11-22 15:49:48,893:INFO:Total runtime is 0.9580262939135233 minutes
2022-11-22 15:49:48,914:INFO:SubProcess create_model() called ==================================
2022-11-22 15:49:48,920:INFO:Initializing create_model()
2022-11-22 15:49:48,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:49:48,925:INFO:Checking exceptions
2022-11-22 15:49:48,934:INFO:Importing libraries
2022-11-22 15:49:48,935:INFO:Copying training dataset
2022-11-22 15:49:49,009:INFO:Defining folds
2022-11-22 15:49:49,013:INFO:Declaring metric variables
2022-11-22 15:49:49,056:INFO:Importing untrained model
2022-11-22 15:49:49,093:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-22 15:49:49,136:INFO:Starting cross validation
2022-11-22 15:49:49,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:49:49,337:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:49,347:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:49,687:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:49,719:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:50,035:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:50,059:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:50,308:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:50,308:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:50,628:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:50,653:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 15:49:51,035:INFO:Calculating mean and std
2022-11-22 15:49:51,051:INFO:Creating metrics dataframe
2022-11-22 15:49:51,073:INFO:Uploading results into container
2022-11-22 15:49:51,075:INFO:Uploading model into container now
2022-11-22 15:49:51,076:INFO:master_model_container: 7
2022-11-22 15:49:51,076:INFO:display_container: 2
2022-11-22 15:49:51,077:INFO:OrthogonalMatchingPursuit()
2022-11-22 15:49:51,077:INFO:create_model() successfully completed......................................
2022-11-22 15:49:51,931:INFO:SubProcess create_model() end ==================================
2022-11-22 15:49:51,931:INFO:Creating metrics dataframe
2022-11-22 15:49:51,989:INFO:Initializing Bayesian Ridge
2022-11-22 15:49:51,989:INFO:Total runtime is 1.0096225301424662 minutes
2022-11-22 15:49:52,014:INFO:SubProcess create_model() called ==================================
2022-11-22 15:49:52,018:INFO:Initializing create_model()
2022-11-22 15:49:52,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:49:52,019:INFO:Checking exceptions
2022-11-22 15:49:52,053:INFO:Importing libraries
2022-11-22 15:49:52,055:INFO:Copying training dataset
2022-11-22 15:49:52,124:INFO:Defining folds
2022-11-22 15:49:52,124:INFO:Declaring metric variables
2022-11-22 15:49:52,219:INFO:Importing untrained model
2022-11-22 15:49:52,269:INFO:Bayesian Ridge Imported successfully
2022-11-22 15:49:52,364:INFO:Starting cross validation
2022-11-22 15:49:52,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:49:54,736:INFO:Calculating mean and std
2022-11-22 15:49:54,806:INFO:Creating metrics dataframe
2022-11-22 15:49:54,823:INFO:Uploading results into container
2022-11-22 15:49:54,825:INFO:Uploading model into container now
2022-11-22 15:49:54,827:INFO:master_model_container: 8
2022-11-22 15:49:54,827:INFO:display_container: 2
2022-11-22 15:49:54,833:INFO:BayesianRidge()
2022-11-22 15:49:54,834:INFO:create_model() successfully completed......................................
2022-11-22 15:49:55,405:INFO:SubProcess create_model() end ==================================
2022-11-22 15:49:55,406:INFO:Creating metrics dataframe
2022-11-22 15:49:55,447:INFO:Initializing Passive Aggressive Regressor
2022-11-22 15:49:55,453:INFO:Total runtime is 1.0673576196034749 minutes
2022-11-22 15:49:55,476:INFO:SubProcess create_model() called ==================================
2022-11-22 15:49:55,476:INFO:Initializing create_model()
2022-11-22 15:49:55,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:49:55,477:INFO:Checking exceptions
2022-11-22 15:49:55,493:INFO:Importing libraries
2022-11-22 15:49:55,493:INFO:Copying training dataset
2022-11-22 15:49:55,590:INFO:Defining folds
2022-11-22 15:49:55,592:INFO:Declaring metric variables
2022-11-22 15:49:55,617:INFO:Importing untrained model
2022-11-22 15:49:55,661:INFO:Passive Aggressive Regressor Imported successfully
2022-11-22 15:49:55,742:INFO:Starting cross validation
2022-11-22 15:49:55,746:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:49:57,943:INFO:Calculating mean and std
2022-11-22 15:49:57,953:INFO:Creating metrics dataframe
2022-11-22 15:49:57,972:INFO:Uploading results into container
2022-11-22 15:49:57,985:INFO:Uploading model into container now
2022-11-22 15:49:57,987:INFO:master_model_container: 9
2022-11-22 15:49:57,989:INFO:display_container: 2
2022-11-22 15:49:57,991:INFO:PassiveAggressiveRegressor(random_state=6230)
2022-11-22 15:49:57,992:INFO:create_model() successfully completed......................................
2022-11-22 15:49:58,494:INFO:SubProcess create_model() end ==================================
2022-11-22 15:49:58,495:INFO:Creating metrics dataframe
2022-11-22 15:49:58,556:INFO:Initializing Huber Regressor
2022-11-22 15:49:58,556:INFO:Total runtime is 1.1190793673197428 minutes
2022-11-22 15:49:58,578:INFO:SubProcess create_model() called ==================================
2022-11-22 15:49:58,588:INFO:Initializing create_model()
2022-11-22 15:49:58,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:49:58,592:INFO:Checking exceptions
2022-11-22 15:49:58,603:INFO:Importing libraries
2022-11-22 15:49:58,603:INFO:Copying training dataset
2022-11-22 15:49:58,654:INFO:Defining folds
2022-11-22 15:49:58,654:INFO:Declaring metric variables
2022-11-22 15:49:58,677:INFO:Importing untrained model
2022-11-22 15:49:58,711:INFO:Huber Regressor Imported successfully
2022-11-22 15:49:58,839:INFO:Starting cross validation
2022-11-22 15:49:58,846:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:49:59,719:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 15:50:00,457:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 15:50:00,772:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 15:50:01,543:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 15:50:01,577:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 15:50:02,112:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 15:50:02,137:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 15:50:02,678:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 15:50:02,679:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 15:50:02,762:INFO:Calculating mean and std
2022-11-22 15:50:02,778:INFO:Creating metrics dataframe
2022-11-22 15:50:02,796:INFO:Uploading results into container
2022-11-22 15:50:02,802:INFO:Uploading model into container now
2022-11-22 15:50:02,805:INFO:master_model_container: 10
2022-11-22 15:50:02,805:INFO:display_container: 2
2022-11-22 15:50:02,806:INFO:HuberRegressor()
2022-11-22 15:50:02,806:INFO:create_model() successfully completed......................................
2022-11-22 15:50:03,308:INFO:SubProcess create_model() end ==================================
2022-11-22 15:50:03,308:INFO:Creating metrics dataframe
2022-11-22 15:50:03,357:INFO:Initializing K Neighbors Regressor
2022-11-22 15:50:03,357:INFO:Total runtime is 1.1990932782491048 minutes
2022-11-22 15:50:03,378:INFO:SubProcess create_model() called ==================================
2022-11-22 15:50:03,385:INFO:Initializing create_model()
2022-11-22 15:50:03,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:50:03,385:INFO:Checking exceptions
2022-11-22 15:50:03,393:INFO:Importing libraries
2022-11-22 15:50:03,393:INFO:Copying training dataset
2022-11-22 15:50:03,508:INFO:Defining folds
2022-11-22 15:50:03,517:INFO:Declaring metric variables
2022-11-22 15:50:03,562:INFO:Importing untrained model
2022-11-22 15:50:03,637:INFO:K Neighbors Regressor Imported successfully
2022-11-22 15:50:03,688:INFO:Starting cross validation
2022-11-22 15:50:03,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:50:05,656:INFO:Calculating mean and std
2022-11-22 15:50:05,666:INFO:Creating metrics dataframe
2022-11-22 15:50:05,687:INFO:Uploading results into container
2022-11-22 15:50:05,689:INFO:Uploading model into container now
2022-11-22 15:50:05,690:INFO:master_model_container: 11
2022-11-22 15:50:05,692:INFO:display_container: 2
2022-11-22 15:50:05,693:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-22 15:50:05,694:INFO:create_model() successfully completed......................................
2022-11-22 15:50:06,254:INFO:SubProcess create_model() end ==================================
2022-11-22 15:50:06,254:INFO:Creating metrics dataframe
2022-11-22 15:50:06,307:INFO:Initializing Decision Tree Regressor
2022-11-22 15:50:06,307:INFO:Total runtime is 1.2482558528582255 minutes
2022-11-22 15:50:06,339:INFO:SubProcess create_model() called ==================================
2022-11-22 15:50:06,344:INFO:Initializing create_model()
2022-11-22 15:50:06,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:50:06,345:INFO:Checking exceptions
2022-11-22 15:50:06,356:INFO:Importing libraries
2022-11-22 15:50:06,356:INFO:Copying training dataset
2022-11-22 15:50:06,487:INFO:Defining folds
2022-11-22 15:50:06,488:INFO:Declaring metric variables
2022-11-22 15:50:06,508:INFO:Importing untrained model
2022-11-22 15:50:06,530:INFO:Decision Tree Regressor Imported successfully
2022-11-22 15:50:06,661:INFO:Starting cross validation
2022-11-22 15:50:06,668:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:50:08,492:INFO:Calculating mean and std
2022-11-22 15:50:08,505:INFO:Creating metrics dataframe
2022-11-22 15:50:08,522:INFO:Uploading results into container
2022-11-22 15:50:08,524:INFO:Uploading model into container now
2022-11-22 15:50:08,525:INFO:master_model_container: 12
2022-11-22 15:50:08,526:INFO:display_container: 2
2022-11-22 15:50:08,526:INFO:DecisionTreeRegressor(random_state=6230)
2022-11-22 15:50:08,527:INFO:create_model() successfully completed......................................
2022-11-22 15:50:09,254:INFO:SubProcess create_model() end ==================================
2022-11-22 15:50:09,254:INFO:Creating metrics dataframe
2022-11-22 15:50:09,306:INFO:Initializing Random Forest Regressor
2022-11-22 15:50:09,307:INFO:Total runtime is 1.2982603470484415 minutes
2022-11-22 15:50:09,338:INFO:SubProcess create_model() called ==================================
2022-11-22 15:50:09,344:INFO:Initializing create_model()
2022-11-22 15:50:09,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:50:09,345:INFO:Checking exceptions
2022-11-22 15:50:09,354:INFO:Importing libraries
2022-11-22 15:50:09,355:INFO:Copying training dataset
2022-11-22 15:50:09,419:INFO:Defining folds
2022-11-22 15:50:09,424:INFO:Declaring metric variables
2022-11-22 15:50:09,444:INFO:Importing untrained model
2022-11-22 15:50:09,476:INFO:Random Forest Regressor Imported successfully
2022-11-22 15:50:09,577:INFO:Starting cross validation
2022-11-22 15:50:09,579:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:50:51,729:INFO:Calculating mean and std
2022-11-22 15:50:51,750:INFO:Creating metrics dataframe
2022-11-22 15:50:51,770:INFO:Uploading results into container
2022-11-22 15:50:51,772:INFO:Uploading model into container now
2022-11-22 15:50:51,773:INFO:master_model_container: 13
2022-11-22 15:50:51,774:INFO:display_container: 2
2022-11-22 15:50:51,775:INFO:RandomForestRegressor(n_jobs=-1, random_state=6230)
2022-11-22 15:50:51,775:INFO:create_model() successfully completed......................................
2022-11-22 15:50:52,309:INFO:SubProcess create_model() end ==================================
2022-11-22 15:50:52,309:INFO:Creating metrics dataframe
2022-11-22 15:50:52,374:INFO:Initializing Extra Trees Regressor
2022-11-22 15:50:52,374:INFO:Total runtime is 2.0160459717114767 minutes
2022-11-22 15:50:52,404:INFO:SubProcess create_model() called ==================================
2022-11-22 15:50:52,405:INFO:Initializing create_model()
2022-11-22 15:50:52,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:50:52,405:INFO:Checking exceptions
2022-11-22 15:50:52,438:INFO:Importing libraries
2022-11-22 15:50:52,438:INFO:Copying training dataset
2022-11-22 15:50:52,494:INFO:Defining folds
2022-11-22 15:50:52,497:INFO:Declaring metric variables
2022-11-22 15:50:52,526:INFO:Importing untrained model
2022-11-22 15:50:52,607:INFO:Extra Trees Regressor Imported successfully
2022-11-22 15:50:52,683:INFO:Starting cross validation
2022-11-22 15:50:52,686:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:51:18,188:INFO:Calculating mean and std
2022-11-22 15:51:18,200:INFO:Creating metrics dataframe
2022-11-22 15:51:18,222:INFO:Uploading results into container
2022-11-22 15:51:18,224:INFO:Uploading model into container now
2022-11-22 15:51:18,226:INFO:master_model_container: 14
2022-11-22 15:51:18,226:INFO:display_container: 2
2022-11-22 15:51:18,229:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6230)
2022-11-22 15:51:18,229:INFO:create_model() successfully completed......................................
2022-11-22 15:51:18,753:INFO:SubProcess create_model() end ==================================
2022-11-22 15:51:18,753:INFO:Creating metrics dataframe
2022-11-22 15:51:18,854:INFO:Initializing AdaBoost Regressor
2022-11-22 15:51:18,854:INFO:Total runtime is 2.457373674710592 minutes
2022-11-22 15:51:18,882:INFO:SubProcess create_model() called ==================================
2022-11-22 15:51:18,885:INFO:Initializing create_model()
2022-11-22 15:51:18,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:51:18,886:INFO:Checking exceptions
2022-11-22 15:51:18,916:INFO:Importing libraries
2022-11-22 15:51:18,917:INFO:Copying training dataset
2022-11-22 15:51:18,954:INFO:Defining folds
2022-11-22 15:51:18,955:INFO:Declaring metric variables
2022-11-22 15:51:18,976:INFO:Importing untrained model
2022-11-22 15:51:19,131:INFO:AdaBoost Regressor Imported successfully
2022-11-22 15:51:19,242:INFO:Starting cross validation
2022-11-22 15:51:19,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:51:28,771:INFO:Calculating mean and std
2022-11-22 15:51:28,777:INFO:Creating metrics dataframe
2022-11-22 15:51:28,797:INFO:Uploading results into container
2022-11-22 15:51:28,798:INFO:Uploading model into container now
2022-11-22 15:51:28,801:INFO:master_model_container: 15
2022-11-22 15:51:28,801:INFO:display_container: 2
2022-11-22 15:51:28,802:INFO:AdaBoostRegressor(random_state=6230)
2022-11-22 15:51:28,803:INFO:create_model() successfully completed......................................
2022-11-22 15:51:29,337:INFO:SubProcess create_model() end ==================================
2022-11-22 15:51:29,338:INFO:Creating metrics dataframe
2022-11-22 15:51:29,398:INFO:Initializing Gradient Boosting Regressor
2022-11-22 15:51:29,398:INFO:Total runtime is 2.6331066687901816 minutes
2022-11-22 15:51:29,432:INFO:SubProcess create_model() called ==================================
2022-11-22 15:51:29,433:INFO:Initializing create_model()
2022-11-22 15:51:29,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:51:29,433:INFO:Checking exceptions
2022-11-22 15:51:29,439:INFO:Importing libraries
2022-11-22 15:51:29,439:INFO:Copying training dataset
2022-11-22 15:51:29,528:INFO:Defining folds
2022-11-22 15:51:29,529:INFO:Declaring metric variables
2022-11-22 15:51:29,603:INFO:Importing untrained model
2022-11-22 15:51:29,655:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 15:51:29,716:INFO:Starting cross validation
2022-11-22 15:51:29,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:51:43,970:INFO:Calculating mean and std
2022-11-22 15:51:43,974:INFO:Creating metrics dataframe
2022-11-22 15:51:43,996:INFO:Uploading results into container
2022-11-22 15:51:43,998:INFO:Uploading model into container now
2022-11-22 15:51:43,999:INFO:master_model_container: 16
2022-11-22 15:51:43,999:INFO:display_container: 2
2022-11-22 15:51:44,002:INFO:GradientBoostingRegressor(random_state=6230)
2022-11-22 15:51:44,002:INFO:create_model() successfully completed......................................
2022-11-22 15:51:44,467:INFO:SubProcess create_model() end ==================================
2022-11-22 15:51:44,467:INFO:Creating metrics dataframe
2022-11-22 15:51:44,523:INFO:Initializing Extreme Gradient Boosting
2022-11-22 15:51:44,524:INFO:Total runtime is 2.8852084239323936 minutes
2022-11-22 15:51:44,597:INFO:SubProcess create_model() called ==================================
2022-11-22 15:51:44,598:INFO:Initializing create_model()
2022-11-22 15:51:44,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:51:44,599:INFO:Checking exceptions
2022-11-22 15:51:44,616:INFO:Importing libraries
2022-11-22 15:51:44,617:INFO:Copying training dataset
2022-11-22 15:51:44,702:INFO:Defining folds
2022-11-22 15:51:44,702:INFO:Declaring metric variables
2022-11-22 15:51:44,739:INFO:Importing untrained model
2022-11-22 15:51:44,778:INFO:Extreme Gradient Boosting Imported successfully
2022-11-22 15:51:44,891:INFO:Starting cross validation
2022-11-22 15:51:44,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:51:57,512:INFO:Calculating mean and std
2022-11-22 15:51:57,517:INFO:Creating metrics dataframe
2022-11-22 15:51:57,539:INFO:Uploading results into container
2022-11-22 15:51:57,547:INFO:Uploading model into container now
2022-11-22 15:51:57,548:INFO:master_model_container: 17
2022-11-22 15:51:57,548:INFO:display_container: 2
2022-11-22 15:51:57,552:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=6230, ...)
2022-11-22 15:51:57,552:INFO:create_model() successfully completed......................................
2022-11-22 15:51:58,083:INFO:SubProcess create_model() end ==================================
2022-11-22 15:51:58,084:INFO:Creating metrics dataframe
2022-11-22 15:51:58,149:INFO:Initializing Light Gradient Boosting Machine
2022-11-22 15:51:58,151:INFO:Total runtime is 3.112333325544993 minutes
2022-11-22 15:51:58,172:INFO:SubProcess create_model() called ==================================
2022-11-22 15:51:58,173:INFO:Initializing create_model()
2022-11-22 15:51:58,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:51:58,178:INFO:Checking exceptions
2022-11-22 15:51:58,188:INFO:Importing libraries
2022-11-22 15:51:58,188:INFO:Copying training dataset
2022-11-22 15:51:58,304:INFO:Defining folds
2022-11-22 15:51:58,305:INFO:Declaring metric variables
2022-11-22 15:51:58,326:INFO:Importing untrained model
2022-11-22 15:51:58,346:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 15:51:58,623:INFO:Starting cross validation
2022-11-22 15:51:58,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:52:03,233:INFO:Calculating mean and std
2022-11-22 15:52:03,247:INFO:Creating metrics dataframe
2022-11-22 15:52:03,264:INFO:Uploading results into container
2022-11-22 15:52:03,266:INFO:Uploading model into container now
2022-11-22 15:52:03,267:INFO:master_model_container: 18
2022-11-22 15:52:03,268:INFO:display_container: 2
2022-11-22 15:52:03,269:INFO:LGBMRegressor(random_state=6230)
2022-11-22 15:52:03,269:INFO:create_model() successfully completed......................................
2022-11-22 15:52:03,773:INFO:SubProcess create_model() end ==================================
2022-11-22 15:52:03,777:INFO:Creating metrics dataframe
2022-11-22 15:52:03,866:INFO:Initializing Dummy Regressor
2022-11-22 15:52:03,866:INFO:Total runtime is 3.2075874686241153 minutes
2022-11-22 15:52:03,896:INFO:SubProcess create_model() called ==================================
2022-11-22 15:52:03,897:INFO:Initializing create_model()
2022-11-22 15:52:03,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B1307FB80>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:52:03,897:INFO:Checking exceptions
2022-11-22 15:52:03,946:INFO:Importing libraries
2022-11-22 15:52:03,951:INFO:Copying training dataset
2022-11-22 15:52:03,994:INFO:Defining folds
2022-11-22 15:52:03,994:INFO:Declaring metric variables
2022-11-22 15:52:04,035:INFO:Importing untrained model
2022-11-22 15:52:04,069:INFO:Dummy Regressor Imported successfully
2022-11-22 15:52:04,166:INFO:Starting cross validation
2022-11-22 15:52:04,169:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:52:05,499:INFO:Calculating mean and std
2022-11-22 15:52:05,516:INFO:Creating metrics dataframe
2022-11-22 15:52:05,535:INFO:Uploading results into container
2022-11-22 15:52:05,537:INFO:Uploading model into container now
2022-11-22 15:52:05,538:INFO:master_model_container: 19
2022-11-22 15:52:05,539:INFO:display_container: 2
2022-11-22 15:52:05,539:INFO:DummyRegressor()
2022-11-22 15:52:05,544:INFO:create_model() successfully completed......................................
2022-11-22 15:52:06,417:INFO:SubProcess create_model() end ==================================
2022-11-22 15:52:06,418:INFO:Creating metrics dataframe
2022-11-22 15:52:06,633:INFO:Initializing create_model()
2022-11-22 15:52:06,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=LGBMRegressor(random_state=6230), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:52:06,634:INFO:Checking exceptions
2022-11-22 15:52:06,652:INFO:Importing libraries
2022-11-22 15:52:06,656:INFO:Copying training dataset
2022-11-22 15:52:06,673:INFO:Defining folds
2022-11-22 15:52:06,674:INFO:Declaring metric variables
2022-11-22 15:52:06,677:INFO:Importing untrained model
2022-11-22 15:52:06,678:INFO:Declaring custom model
2022-11-22 15:52:06,695:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 15:52:06,697:INFO:Cross validation set to False
2022-11-22 15:52:06,698:INFO:Fitting Model
2022-11-22 15:52:07,416:INFO:LGBMRegressor(random_state=6230)
2022-11-22 15:52:07,416:INFO:create_model() successfully completed......................................
2022-11-22 15:52:08,914:INFO:master_model_container: 19
2022-11-22 15:52:08,914:INFO:display_container: 2
2022-11-22 15:52:08,915:INFO:LGBMRegressor(random_state=6230)
2022-11-22 15:52:08,915:INFO:compare_models() successfully completed......................................
2022-11-22 15:52:33,353:INFO:Initializing create_model()
2022-11-22 15:52:33,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:52:33,354:INFO:Checking exceptions
2022-11-22 15:52:33,532:INFO:Importing libraries
2022-11-22 15:52:33,532:INFO:Copying training dataset
2022-11-22 15:52:33,599:INFO:Defining folds
2022-11-22 15:52:33,599:INFO:Declaring metric variables
2022-11-22 15:52:33,632:INFO:Importing untrained model
2022-11-22 15:52:33,752:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 15:52:33,796:INFO:Starting cross validation
2022-11-22 15:52:33,799:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:52:40,486:INFO:Calculating mean and std
2022-11-22 15:52:40,511:INFO:Creating metrics dataframe
2022-11-22 15:52:40,537:INFO:Finalizing model
2022-11-22 15:52:41,814:INFO:Uploading results into container
2022-11-22 15:52:41,816:INFO:Uploading model into container now
2022-11-22 15:52:42,047:INFO:master_model_container: 20
2022-11-22 15:52:42,047:INFO:display_container: 3
2022-11-22 15:52:42,048:INFO:LGBMRegressor(random_state=6230)
2022-11-22 15:52:42,048:INFO:create_model() successfully completed......................................
2022-11-22 15:52:44,103:INFO:Initializing plot_model()
2022-11-22 15:52:44,103:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=6230), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, system=True)
2022-11-22 15:52:44,104:INFO:Checking exceptions
2022-11-22 15:52:44,230:INFO:Preloading libraries
2022-11-22 15:52:44,502:INFO:Copying training dataset
2022-11-22 15:52:44,502:INFO:Plot type: feature
2022-11-22 15:52:44,503:WARNING:No coef_ found. Trying feature_importances_
2022-11-22 15:52:47,014:INFO:Visual Rendered Successfully
2022-11-22 15:52:47,979:INFO:plot_model() successfully completed......................................
2022-11-22 15:52:56,612:INFO:Initializing tune_model()
2022-11-22 15:52:56,613:INFO:tune_model(estimator=LGBMRegressor(random_state=6230), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>)
2022-11-22 15:52:56,613:INFO:Checking exceptions
2022-11-22 15:52:56,776:INFO:Copying training dataset
2022-11-22 15:52:56,895:INFO:Checking base model
2022-11-22 15:52:56,895:INFO:Base model : Light Gradient Boosting Machine
2022-11-22 15:52:56,946:INFO:Declaring metric variables
2022-11-22 15:52:56,969:INFO:Defining Hyperparameters
2022-11-22 15:52:58,067:INFO:Tuning with n_jobs=-1
2022-11-22 15:52:58,067:INFO:Initializing RandomizedSearchCV
2022-11-22 15:53:48,007:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 1e-06, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 51, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.9}
2022-11-22 15:53:48,013:INFO:Hyperparameter search completed
2022-11-22 15:53:48,015:INFO:SubProcess create_model() called ==================================
2022-11-22 15:53:48,017:INFO:Initializing create_model()
2022-11-22 15:53:48,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=LGBMRegressor(random_state=6230), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020B19473C70>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 2, 'reg_alpha': 1e-06, 'num_leaves': 256, 'n_estimators': 180, 'min_split_gain': 0.5, 'min_child_samples': 51, 'learning_rate': 0.2, 'feature_fraction': 0.5, 'bagging_freq': 1, 'bagging_fraction': 0.9})
2022-11-22 15:53:48,026:INFO:Checking exceptions
2022-11-22 15:53:48,036:INFO:Importing libraries
2022-11-22 15:53:48,037:INFO:Copying training dataset
2022-11-22 15:53:48,053:INFO:Defining folds
2022-11-22 15:53:48,055:INFO:Declaring metric variables
2022-11-22 15:53:48,073:INFO:Importing untrained model
2022-11-22 15:53:48,074:INFO:Declaring custom model
2022-11-22 15:53:48,094:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 15:53:48,159:INFO:Starting cross validation
2022-11-22 15:53:48,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:53:57,796:INFO:Calculating mean and std
2022-11-22 15:53:57,826:INFO:Creating metrics dataframe
2022-11-22 15:53:57,881:INFO:Finalizing model
2022-11-22 15:54:05,490:INFO:Uploading results into container
2022-11-22 15:54:05,491:INFO:Uploading model into container now
2022-11-22 15:54:05,493:INFO:master_model_container: 21
2022-11-22 15:54:05,493:INFO:display_container: 4
2022-11-22 15:54:05,495:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, feature_fraction=0.5,
              learning_rate=0.2, min_child_samples=51, min_split_gain=0.5,
              n_estimators=180, num_leaves=256, random_state=6230,
              reg_alpha=1e-06, reg_lambda=2)
2022-11-22 15:54:05,495:INFO:create_model() successfully completed......................................
2022-11-22 15:54:06,912:INFO:SubProcess create_model() end ==================================
2022-11-22 15:54:06,912:INFO:choose_better activated
2022-11-22 15:54:06,933:INFO:SubProcess create_model() called ==================================
2022-11-22 15:54:06,945:INFO:Initializing create_model()
2022-11-22 15:54:06,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, estimator=LGBMRegressor(random_state=6230), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 15:54:06,945:INFO:Checking exceptions
2022-11-22 15:54:07,127:INFO:Importing libraries
2022-11-22 15:54:07,129:INFO:Copying training dataset
2022-11-22 15:54:07,150:INFO:Defining folds
2022-11-22 15:54:07,154:INFO:Declaring metric variables
2022-11-22 15:54:07,157:INFO:Importing untrained model
2022-11-22 15:54:07,157:INFO:Declaring custom model
2022-11-22 15:54:07,159:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 15:54:07,164:INFO:Starting cross validation
2022-11-22 15:54:07,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 15:54:16,215:INFO:Calculating mean and std
2022-11-22 15:54:16,218:INFO:Creating metrics dataframe
2022-11-22 15:54:16,229:INFO:Finalizing model
2022-11-22 15:54:17,998:INFO:Uploading results into container
2022-11-22 15:54:18,007:INFO:Uploading model into container now
2022-11-22 15:54:18,008:INFO:master_model_container: 22
2022-11-22 15:54:18,008:INFO:display_container: 5
2022-11-22 15:54:18,009:INFO:LGBMRegressor(random_state=6230)
2022-11-22 15:54:18,010:INFO:create_model() successfully completed......................................
2022-11-22 15:54:19,439:INFO:SubProcess create_model() end ==================================
2022-11-22 15:54:19,448:INFO:LGBMRegressor(random_state=6230) result for R2 is 0.8509
2022-11-22 15:54:19,452:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, feature_fraction=0.5,
              learning_rate=0.2, min_child_samples=51, min_split_gain=0.5,
              n_estimators=180, num_leaves=256, random_state=6230,
              reg_alpha=1e-06, reg_lambda=2) result for R2 is 0.847
2022-11-22 15:54:19,453:INFO:LGBMRegressor(random_state=6230) is best model
2022-11-22 15:54:19,453:INFO:choose_better completed
2022-11-22 15:54:19,454:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-11-22 15:54:19,523:INFO:master_model_container: 22
2022-11-22 15:54:19,523:INFO:display_container: 4
2022-11-22 15:54:19,526:INFO:LGBMRegressor(random_state=6230)
2022-11-22 15:54:19,526:INFO:tune_model() successfully completed......................................
2022-11-22 15:55:04,360:INFO:Initializing plot_model()
2022-11-22 15:55:04,361:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=6230), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020B1307FB20>, system=True)
2022-11-22 15:55:04,361:INFO:Checking exceptions
2022-11-22 15:55:04,375:INFO:Preloading libraries
2022-11-22 15:55:04,419:INFO:Copying training dataset
2022-11-22 15:55:04,419:INFO:Plot type: residuals
2022-11-22 15:55:05,906:INFO:Fitting Model
2022-11-22 15:55:07,037:INFO:Scoring test/hold-out set
2022-11-22 15:55:10,733:INFO:Visual Rendered Successfully
2022-11-22 15:55:12,027:INFO:plot_model() successfully completed......................................
2022-11-22 15:55:29,008:INFO:Initializing save_model()
2022-11-22 15:55:29,009:INFO:save_model(model=LGBMRegressor(random_state=6230), model_name=Coches_gbr, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\nacho\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-11-22 15:55:29,009:INFO:Adding model into prep_pipe
2022-11-22 15:55:29,054:INFO:Coches_gbr.pkl saved in current working directory
2022-11-22 15:55:29,075:INFO:Pipeline(memory=Memory(location=C:\Users\nacho\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model', LGBMRegressor(random_state=6230))])
2022-11-22 15:55:29,075:INFO:save_model() successfully completed......................................
2022-11-23 11:45:27,779:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-23 11:45:27,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-23 11:45:27,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-23 11:45:27,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-23 11:46:22,151:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-11-23 11:46:27,878:INFO:PyCaret RegressionExperiment
2022-11-23 11:46:27,879:INFO:Logging name: reg-default-name
2022-11-23 11:46:27,879:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-23 11:46:27,880:INFO:version 3.0.0.rc4
2022-11-23 11:46:27,882:INFO:Initializing setup()
2022-11-23 11:46:27,884:INFO:self.USI: 1f3b
2022-11-23 11:46:27,884:INFO:self.variable_keys: {'log_plots_param', 'X_train', 'display_container', 'fold_generator', '_gpu_n_jobs_param', '_ml_usecase', 'data', '_all_models_internal', 'variable_keys', 'exp_name_log', 'n_jobs_param', 'y_test', 'logging_param', 'html_param', 'pipeline', 'gpu_param', 'X', 'idx', 'transform_target_param', 'y', 'master_model_container', 'fold_groups_param', 'target_param', '_available_plots', 'X_test', 'memory', 'fold_shuffle_param', 'y_train', 'transform_target_method_param', 'exp_id', '_all_metrics', 'USI', '_all_models', 'seed'}
2022-11-23 11:46:27,884:INFO:Checking environment
2022-11-23 11:46:27,891:INFO:python_version: 3.10.7
2022-11-23 11:46:27,892:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-11-23 11:46:27,892:INFO:machine: AMD64
2022-11-23 11:46:27,892:INFO:platform: Windows-10-10.0.19044-SP0
2022-11-23 11:46:27,946:INFO:Memory: svmem(total=8017076224, available=1497747456, percent=81.3, used=6519328768, free=1497747456)
2022-11-23 11:46:27,947:INFO:Physical Core: 2
2022-11-23 11:46:27,947:INFO:Logical Core: 2
2022-11-23 11:46:27,947:INFO:Checking libraries
2022-11-23 11:46:27,947:INFO:System:
2022-11-23 11:46:27,947:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-11-23 11:46:27,957:INFO:executable: c:\Users\nacho\ignacio-boot\venv_analitycs\Scripts\python.exe
2022-11-23 11:46:27,957:INFO:   machine: Windows-10-10.0.19044-SP0
2022-11-23 11:46:27,957:INFO:PyCaret required dependencies:
2022-11-23 11:46:27,957:INFO:                 pip: 22.3.1
2022-11-23 11:46:27,959:INFO:          setuptools: 63.2.0
2022-11-23 11:46:27,959:INFO:             pycaret: 3.0.0rc4
2022-11-23 11:46:27,959:INFO:             IPython: 8.5.0
2022-11-23 11:46:27,959:INFO:          ipywidgets: 8.0.2
2022-11-23 11:46:27,964:INFO:                tqdm: 4.64.1
2022-11-23 11:46:27,964:INFO:               numpy: 1.22.4
2022-11-23 11:46:27,964:INFO:              pandas: 1.4.4
2022-11-23 11:46:27,965:INFO:              jinja2: 3.1.2
2022-11-23 11:46:27,965:INFO:               scipy: 1.8.1
2022-11-23 11:46:27,965:INFO:              joblib: 1.2.0
2022-11-23 11:46:27,965:INFO:             sklearn: 1.1.2
2022-11-23 11:46:27,965:INFO:                pyod: 1.0.6
2022-11-23 11:46:27,966:INFO:            imblearn: 0.9.1
2022-11-23 11:46:27,967:INFO:   category_encoders: 2.5.1.post0
2022-11-23 11:46:27,977:INFO:            lightgbm: 3.3.3
2022-11-23 11:46:27,977:INFO:               numba: 0.55.2
2022-11-23 11:46:27,977:INFO:            requests: 2.28.1
2022-11-23 11:46:27,978:INFO:          matplotlib: 3.6.0
2022-11-23 11:46:27,978:INFO:          scikitplot: 0.3.7
2022-11-23 11:46:27,978:INFO:         yellowbrick: 1.5
2022-11-23 11:46:27,978:INFO:              plotly: 5.10.0
2022-11-23 11:46:27,978:INFO:             kaleido: 0.2.1
2022-11-23 11:46:27,978:INFO:         statsmodels: 0.13.2
2022-11-23 11:46:27,979:INFO:              sktime: 0.13.4
2022-11-23 11:46:27,979:INFO:               tbats: 1.1.1
2022-11-23 11:46:27,980:INFO:            pmdarima: 1.8.5
2022-11-23 11:46:27,980:INFO:              psutil: 5.9.2
2022-11-23 11:46:27,980:INFO:PyCaret optional dependencies:
2022-11-23 11:46:28,366:INFO:                shap: Not installed
2022-11-23 11:46:28,367:INFO:           interpret: Not installed
2022-11-23 11:46:28,367:INFO:                umap: Not installed
2022-11-23 11:46:28,367:INFO:    pandas_profiling: Not installed
2022-11-23 11:46:28,367:INFO:  explainerdashboard: Not installed
2022-11-23 11:46:28,367:INFO:             autoviz: Not installed
2022-11-23 11:46:28,369:INFO:           fairlearn: Not installed
2022-11-23 11:46:28,378:INFO:             xgboost: 1.7.1
2022-11-23 11:46:28,379:INFO:            catboost: Not installed
2022-11-23 11:46:28,379:INFO:              kmodes: Not installed
2022-11-23 11:46:28,381:INFO:             mlxtend: Not installed
2022-11-23 11:46:28,384:INFO:       statsforecast: Not installed
2022-11-23 11:46:28,385:INFO:        tune_sklearn: Not installed
2022-11-23 11:46:28,385:INFO:                 ray: Not installed
2022-11-23 11:46:28,385:INFO:            hyperopt: Not installed
2022-11-23 11:46:28,385:INFO:              optuna: 3.0.3
2022-11-23 11:46:28,398:INFO:               skopt: 0.9.0
2022-11-23 11:46:28,415:INFO:              mlflow: Not installed
2022-11-23 11:46:28,415:INFO:              gradio: Not installed
2022-11-23 11:46:28,415:INFO:             fastapi: Not installed
2022-11-23 11:46:28,416:INFO:             uvicorn: Not installed
2022-11-23 11:46:28,417:INFO:              m2cgen: Not installed
2022-11-23 11:46:28,417:INFO:           evidently: Not installed
2022-11-23 11:46:28,417:INFO:                nltk: Not installed
2022-11-23 11:46:28,418:INFO:            pyLDAvis: Not installed
2022-11-23 11:46:28,418:INFO:              gensim: Not installed
2022-11-23 11:46:28,418:INFO:               spacy: Not installed
2022-11-23 11:46:28,426:INFO:           wordcloud: 1.8.2.2
2022-11-23 11:46:28,427:INFO:            textblob: Not installed
2022-11-23 11:46:28,427:INFO:               fugue: Not installed
2022-11-23 11:46:28,428:INFO:           streamlit: 1.15.0
2022-11-23 11:46:28,428:INFO:             prophet: Not installed
2022-11-23 11:46:28,428:INFO:None
2022-11-23 11:46:28,432:INFO:Set up data.
2022-11-23 11:46:28,506:INFO:Set up train/test split.
2022-11-23 11:46:28,610:INFO:Set up index.
2022-11-23 11:46:28,612:INFO:Set up folding strategy.
2022-11-23 11:46:28,613:INFO:Assigning column types.
2022-11-23 11:46:28,661:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-23 11:46:28,662:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-23 11:46:28,699:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-23 11:46:28,860:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-23 11:46:30,295:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-23 11:46:30,951:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-23 11:46:30,961:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:34,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:35,000:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-23 11:46:35,079:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-23 11:46:35,115:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-23 11:46:35,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-23 11:46:36,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-23 11:46:36,143:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:36,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:36,161:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-23 11:46:36,226:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-23 11:46:36,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-23 11:46:36,809:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-23 11:46:37,262:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-23 11:46:37,265:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:37,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:37,342:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-23 11:46:37,366:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-23 11:46:37,863:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-23 11:46:38,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-23 11:46:38,310:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:38,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:38,334:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-23 11:46:38,426:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-23 11:46:38,967:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-23 11:46:39,344:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-23 11:46:39,346:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:39,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:39,445:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-23 11:46:40,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-23 11:46:40,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-23 11:46:40,616:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:40,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:40,634:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-23 11:46:41,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-23 11:46:41,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-23 11:46:41,346:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:41,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:41,816:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-23 11:46:42,228:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-23 11:46:42,230:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:42,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:42,246:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-23 11:46:42,930:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-23 11:46:43,315:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:43,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:43,963:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-23 11:46:44,364:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:44,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:44,416:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-23 11:46:45,466:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:45,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:46,483:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:46,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:46,583:INFO:Preparing preprocessing pipeline...
2022-11-23 11:46:46,596:INFO:Set up simple imputation.
2022-11-23 11:46:46,597:INFO:Set up variance threshold.
2022-11-23 11:46:47,180:INFO:Finished creating preprocessing pipeline.
2022-11-23 11:46:47,226:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\nacho\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-23 11:46:47,226:INFO:Creating final display dataframe.
2022-11-23 11:46:49,841:INFO:Setup display_container:                Description             Value
0               Session id              3936
1                   Target             price
2              Target type        Regression
3               Data shape        (5000, 13)
4         Train data shape        (3499, 13)
5          Test data shape        (1501, 13)
6         Numeric features                12
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              1f3b
2022-11-23 11:46:50,963:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:50,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:52,243:INFO:Soft dependency imported: xgboost: 1.7.1
2022-11-23 11:46:52,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-23 11:46:52,377:INFO:setup() successfully completed in 24.54s...............
2022-11-23 11:46:52,923:INFO:Initializing compare_models()
2022-11-23 11:46:52,923:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-23 11:46:52,924:INFO:Checking exceptions
2022-11-23 11:46:52,932:INFO:Preparing display monitor
2022-11-23 11:46:53,483:INFO:Initializing Linear Regression
2022-11-23 11:46:53,483:INFO:Total runtime is 0.0 minutes
2022-11-23 11:46:53,599:INFO:SubProcess create_model() called ==================================
2022-11-23 11:46:53,607:INFO:Initializing create_model()
2022-11-23 11:46:53,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:46:53,608:INFO:Checking exceptions
2022-11-23 11:46:53,624:INFO:Importing libraries
2022-11-23 11:46:53,625:INFO:Copying training dataset
2022-11-23 11:46:53,664:INFO:Defining folds
2022-11-23 11:46:53,665:INFO:Declaring metric variables
2022-11-23 11:46:53,711:INFO:Importing untrained model
2022-11-23 11:46:53,743:INFO:Linear Regression Imported successfully
2022-11-23 11:46:53,829:INFO:Starting cross validation
2022-11-23 11:46:53,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:48:05,202:INFO:Calculating mean and std
2022-11-23 11:48:05,220:INFO:Creating metrics dataframe
2022-11-23 11:48:05,239:INFO:Uploading results into container
2022-11-23 11:48:05,240:INFO:Uploading model into container now
2022-11-23 11:48:05,241:INFO:master_model_container: 1
2022-11-23 11:48:05,241:INFO:display_container: 2
2022-11-23 11:48:05,242:INFO:LinearRegression(n_jobs=-1)
2022-11-23 11:48:05,243:INFO:create_model() successfully completed......................................
2022-11-23 11:48:07,459:INFO:SubProcess create_model() end ==================================
2022-11-23 11:48:07,459:INFO:Creating metrics dataframe
2022-11-23 11:48:07,558:INFO:Initializing Lasso Regression
2022-11-23 11:48:07,558:INFO:Total runtime is 1.2345801711082458 minutes
2022-11-23 11:48:07,622:INFO:SubProcess create_model() called ==================================
2022-11-23 11:48:07,623:INFO:Initializing create_model()
2022-11-23 11:48:07,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:48:07,624:INFO:Checking exceptions
2022-11-23 11:48:07,639:INFO:Importing libraries
2022-11-23 11:48:07,639:INFO:Copying training dataset
2022-11-23 11:48:07,858:INFO:Defining folds
2022-11-23 11:48:07,859:INFO:Declaring metric variables
2022-11-23 11:48:07,905:INFO:Importing untrained model
2022-11-23 11:48:07,924:INFO:Lasso Regression Imported successfully
2022-11-23 11:48:08,160:INFO:Starting cross validation
2022-11-23 11:48:08,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:48:17,959:INFO:Calculating mean and std
2022-11-23 11:48:17,975:INFO:Creating metrics dataframe
2022-11-23 11:48:18,021:INFO:Uploading results into container
2022-11-23 11:48:18,023:INFO:Uploading model into container now
2022-11-23 11:48:18,025:INFO:master_model_container: 2
2022-11-23 11:48:18,027:INFO:display_container: 2
2022-11-23 11:48:18,035:INFO:Lasso(random_state=3936)
2022-11-23 11:48:18,037:INFO:create_model() successfully completed......................................
2022-11-23 11:48:21,129:INFO:SubProcess create_model() end ==================================
2022-11-23 11:48:21,140:INFO:Creating metrics dataframe
2022-11-23 11:48:21,361:INFO:Initializing Ridge Regression
2022-11-23 11:48:21,370:INFO:Total runtime is 1.4647725701332093 minutes
2022-11-23 11:48:21,390:INFO:SubProcess create_model() called ==================================
2022-11-23 11:48:21,391:INFO:Initializing create_model()
2022-11-23 11:48:21,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:48:21,391:INFO:Checking exceptions
2022-11-23 11:48:21,474:INFO:Importing libraries
2022-11-23 11:48:21,474:INFO:Copying training dataset
2022-11-23 11:48:21,537:INFO:Defining folds
2022-11-23 11:48:21,538:INFO:Declaring metric variables
2022-11-23 11:48:21,559:INFO:Importing untrained model
2022-11-23 11:48:21,723:INFO:Ridge Regression Imported successfully
2022-11-23 11:48:22,078:INFO:Starting cross validation
2022-11-23 11:48:22,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:48:29,786:INFO:Calculating mean and std
2022-11-23 11:48:29,820:INFO:Creating metrics dataframe
2022-11-23 11:48:29,850:INFO:Uploading results into container
2022-11-23 11:48:29,854:INFO:Uploading model into container now
2022-11-23 11:48:29,858:INFO:master_model_container: 3
2022-11-23 11:48:29,859:INFO:display_container: 2
2022-11-23 11:48:29,860:INFO:Ridge(random_state=3936)
2022-11-23 11:48:29,860:INFO:create_model() successfully completed......................................
2022-11-23 11:48:37,651:INFO:SubProcess create_model() end ==================================
2022-11-23 11:48:37,652:INFO:Creating metrics dataframe
2022-11-23 11:48:38,418:INFO:Initializing Elastic Net
2022-11-23 11:48:38,418:INFO:Total runtime is 1.74890988667806 minutes
2022-11-23 11:48:38,460:INFO:SubProcess create_model() called ==================================
2022-11-23 11:48:38,465:INFO:Initializing create_model()
2022-11-23 11:48:38,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:48:38,465:INFO:Checking exceptions
2022-11-23 11:48:38,800:INFO:Importing libraries
2022-11-23 11:48:38,801:INFO:Copying training dataset
2022-11-23 11:48:38,882:INFO:Defining folds
2022-11-23 11:48:38,883:INFO:Declaring metric variables
2022-11-23 11:48:38,935:INFO:Importing untrained model
2022-11-23 11:48:39,374:INFO:Elastic Net Imported successfully
2022-11-23 11:48:39,737:INFO:Starting cross validation
2022-11-23 11:48:39,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:48:47,253:INFO:Calculating mean and std
2022-11-23 11:48:47,266:INFO:Creating metrics dataframe
2022-11-23 11:48:47,302:INFO:Uploading results into container
2022-11-23 11:48:47,304:INFO:Uploading model into container now
2022-11-23 11:48:47,305:INFO:master_model_container: 4
2022-11-23 11:48:47,306:INFO:display_container: 2
2022-11-23 11:48:47,310:INFO:ElasticNet(random_state=3936)
2022-11-23 11:48:47,310:INFO:create_model() successfully completed......................................
2022-11-23 11:48:51,502:INFO:SubProcess create_model() end ==================================
2022-11-23 11:48:51,502:INFO:Creating metrics dataframe
2022-11-23 11:48:51,660:INFO:Initializing Least Angle Regression
2022-11-23 11:48:51,666:INFO:Total runtime is 1.969710107644399 minutes
2022-11-23 11:48:51,690:INFO:SubProcess create_model() called ==================================
2022-11-23 11:48:51,692:INFO:Initializing create_model()
2022-11-23 11:48:51,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:48:51,693:INFO:Checking exceptions
2022-11-23 11:48:51,702:INFO:Importing libraries
2022-11-23 11:48:51,703:INFO:Copying training dataset
2022-11-23 11:48:51,914:INFO:Defining folds
2022-11-23 11:48:51,914:INFO:Declaring metric variables
2022-11-23 11:48:51,990:INFO:Importing untrained model
2022-11-23 11:48:52,208:INFO:Least Angle Regression Imported successfully
2022-11-23 11:48:52,573:INFO:Starting cross validation
2022-11-23 11:48:52,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:48:53,509:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:48:53,726:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:48:54,842:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:48:55,020:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:48:55,760:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:48:55,860:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:48:56,721:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:48:56,924:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:48:57,758:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:48:57,858:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:48:58,391:INFO:Calculating mean and std
2022-11-23 11:48:58,404:INFO:Creating metrics dataframe
2022-11-23 11:48:58,422:INFO:Uploading results into container
2022-11-23 11:48:58,424:INFO:Uploading model into container now
2022-11-23 11:48:58,425:INFO:master_model_container: 5
2022-11-23 11:48:58,425:INFO:display_container: 2
2022-11-23 11:48:58,426:INFO:Lars(random_state=3936)
2022-11-23 11:48:58,426:INFO:create_model() successfully completed......................................
2022-11-23 11:49:02,005:INFO:SubProcess create_model() end ==================================
2022-11-23 11:49:02,005:INFO:Creating metrics dataframe
2022-11-23 11:49:02,216:INFO:Initializing Lasso Least Angle Regression
2022-11-23 11:49:02,217:INFO:Total runtime is 2.1455613295237224 minutes
2022-11-23 11:49:02,254:INFO:SubProcess create_model() called ==================================
2022-11-23 11:49:02,255:INFO:Initializing create_model()
2022-11-23 11:49:02,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:49:02,256:INFO:Checking exceptions
2022-11-23 11:49:02,309:INFO:Importing libraries
2022-11-23 11:49:02,309:INFO:Copying training dataset
2022-11-23 11:49:02,359:INFO:Defining folds
2022-11-23 11:49:02,366:INFO:Declaring metric variables
2022-11-23 11:49:02,458:INFO:Importing untrained model
2022-11-23 11:49:02,485:INFO:Lasso Least Angle Regression Imported successfully
2022-11-23 11:49:02,684:INFO:Starting cross validation
2022-11-23 11:49:02,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:49:02,885:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-23 11:49:02,917:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-23 11:49:04,004:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-23 11:49:04,069:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-23 11:49:04,943:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-23 11:49:04,982:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-23 11:49:05,905:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-23 11:49:06,038:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-23 11:49:06,688:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-23 11:49:06,765:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-23 11:49:06,983:INFO:Calculating mean and std
2022-11-23 11:49:06,999:INFO:Creating metrics dataframe
2022-11-23 11:49:07,020:INFO:Uploading results into container
2022-11-23 11:49:07,022:INFO:Uploading model into container now
2022-11-23 11:49:07,023:INFO:master_model_container: 6
2022-11-23 11:49:07,024:INFO:display_container: 2
2022-11-23 11:49:07,025:INFO:LassoLars(random_state=3936)
2022-11-23 11:49:07,025:INFO:create_model() successfully completed......................................
2022-11-23 11:49:09,502:INFO:SubProcess create_model() end ==================================
2022-11-23 11:49:09,502:INFO:Creating metrics dataframe
2022-11-23 11:49:09,721:INFO:Initializing Orthogonal Matching Pursuit
2022-11-23 11:49:09,721:INFO:Total runtime is 2.270632549126943 minutes
2022-11-23 11:49:09,749:INFO:SubProcess create_model() called ==================================
2022-11-23 11:49:09,750:INFO:Initializing create_model()
2022-11-23 11:49:09,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:49:09,751:INFO:Checking exceptions
2022-11-23 11:49:09,759:INFO:Importing libraries
2022-11-23 11:49:09,938:INFO:Copying training dataset
2022-11-23 11:49:10,000:INFO:Defining folds
2022-11-23 11:49:10,002:INFO:Declaring metric variables
2022-11-23 11:49:10,037:INFO:Importing untrained model
2022-11-23 11:49:10,290:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-23 11:49:10,340:INFO:Starting cross validation
2022-11-23 11:49:10,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:49:10,809:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:49:10,834:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:49:11,555:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:49:11,886:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:49:12,937:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:49:13,267:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:49:13,850:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:49:14,255:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:49:14,735:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:49:15,142:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-23 11:49:15,492:INFO:Calculating mean and std
2022-11-23 11:49:15,504:INFO:Creating metrics dataframe
2022-11-23 11:49:15,535:INFO:Uploading results into container
2022-11-23 11:49:15,537:INFO:Uploading model into container now
2022-11-23 11:49:15,538:INFO:master_model_container: 7
2022-11-23 11:49:15,539:INFO:display_container: 2
2022-11-23 11:49:15,540:INFO:OrthogonalMatchingPursuit()
2022-11-23 11:49:15,540:INFO:create_model() successfully completed......................................
2022-11-23 11:49:18,351:INFO:SubProcess create_model() end ==================================
2022-11-23 11:49:18,352:INFO:Creating metrics dataframe
2022-11-23 11:49:18,505:INFO:Initializing Bayesian Ridge
2022-11-23 11:49:18,506:INFO:Total runtime is 2.417045537630717 minutes
2022-11-23 11:49:18,696:INFO:SubProcess create_model() called ==================================
2022-11-23 11:49:18,697:INFO:Initializing create_model()
2022-11-23 11:49:18,697:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:49:18,698:INFO:Checking exceptions
2022-11-23 11:49:18,721:INFO:Importing libraries
2022-11-23 11:49:18,722:INFO:Copying training dataset
2022-11-23 11:49:18,974:INFO:Defining folds
2022-11-23 11:49:18,975:INFO:Declaring metric variables
2022-11-23 11:49:19,013:INFO:Importing untrained model
2022-11-23 11:49:19,042:INFO:Bayesian Ridge Imported successfully
2022-11-23 11:49:19,292:INFO:Starting cross validation
2022-11-23 11:49:19,300:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:49:23,724:INFO:Calculating mean and std
2022-11-23 11:49:23,749:INFO:Creating metrics dataframe
2022-11-23 11:49:23,773:INFO:Uploading results into container
2022-11-23 11:49:23,775:INFO:Uploading model into container now
2022-11-23 11:49:23,780:INFO:master_model_container: 8
2022-11-23 11:49:23,780:INFO:display_container: 2
2022-11-23 11:49:23,780:INFO:BayesianRidge()
2022-11-23 11:49:23,781:INFO:create_model() successfully completed......................................
2022-11-23 11:49:25,983:INFO:SubProcess create_model() end ==================================
2022-11-23 11:49:25,984:INFO:Creating metrics dataframe
2022-11-23 11:49:26,150:INFO:Initializing Passive Aggressive Regressor
2022-11-23 11:49:26,152:INFO:Total runtime is 2.5444781502087914 minutes
2022-11-23 11:49:26,190:INFO:SubProcess create_model() called ==================================
2022-11-23 11:49:26,196:INFO:Initializing create_model()
2022-11-23 11:49:26,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:49:26,196:INFO:Checking exceptions
2022-11-23 11:49:26,203:INFO:Importing libraries
2022-11-23 11:49:26,204:INFO:Copying training dataset
2022-11-23 11:49:26,303:INFO:Defining folds
2022-11-23 11:49:26,303:INFO:Declaring metric variables
2022-11-23 11:49:26,323:INFO:Importing untrained model
2022-11-23 11:49:26,349:INFO:Passive Aggressive Regressor Imported successfully
2022-11-23 11:49:26,436:INFO:Starting cross validation
2022-11-23 11:49:26,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:49:31,557:INFO:Calculating mean and std
2022-11-23 11:49:31,575:INFO:Creating metrics dataframe
2022-11-23 11:49:31,605:INFO:Uploading results into container
2022-11-23 11:49:31,608:INFO:Uploading model into container now
2022-11-23 11:49:31,616:INFO:master_model_container: 9
2022-11-23 11:49:31,617:INFO:display_container: 2
2022-11-23 11:49:31,617:INFO:PassiveAggressiveRegressor(random_state=3936)
2022-11-23 11:49:31,618:INFO:create_model() successfully completed......................................
2022-11-23 11:49:34,281:INFO:SubProcess create_model() end ==================================
2022-11-23 11:49:34,281:INFO:Creating metrics dataframe
2022-11-23 11:49:34,457:INFO:Initializing Huber Regressor
2022-11-23 11:49:34,460:INFO:Total runtime is 2.682954021294912 minutes
2022-11-23 11:49:34,484:INFO:SubProcess create_model() called ==================================
2022-11-23 11:49:34,485:INFO:Initializing create_model()
2022-11-23 11:49:34,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:49:34,490:INFO:Checking exceptions
2022-11-23 11:49:34,586:INFO:Importing libraries
2022-11-23 11:49:34,597:INFO:Copying training dataset
2022-11-23 11:49:34,640:INFO:Defining folds
2022-11-23 11:49:34,641:INFO:Declaring metric variables
2022-11-23 11:49:34,680:INFO:Importing untrained model
2022-11-23 11:49:34,771:INFO:Huber Regressor Imported successfully
2022-11-23 11:49:34,923:INFO:Starting cross validation
2022-11-23 11:49:34,933:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:49:37,065:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-23 11:49:37,339:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-23 11:49:40,804:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-23 11:49:40,851:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-23 11:49:42,904:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-23 11:49:42,917:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-23 11:49:44,935:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-23 11:49:45,236:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-23 11:49:47,340:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-23 11:49:47,485:WARNING:c:\Users\nacho\ignacio-boot\venv_analitycs\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-23 11:49:47,700:INFO:Calculating mean and std
2022-11-23 11:49:47,721:INFO:Creating metrics dataframe
2022-11-23 11:49:47,763:INFO:Uploading results into container
2022-11-23 11:49:47,765:INFO:Uploading model into container now
2022-11-23 11:49:47,766:INFO:master_model_container: 10
2022-11-23 11:49:47,768:INFO:display_container: 2
2022-11-23 11:49:47,769:INFO:HuberRegressor()
2022-11-23 11:49:47,769:INFO:create_model() successfully completed......................................
2022-11-23 11:49:50,383:INFO:SubProcess create_model() end ==================================
2022-11-23 11:49:50,383:INFO:Creating metrics dataframe
2022-11-23 11:49:50,763:INFO:Initializing K Neighbors Regressor
2022-11-23 11:49:50,764:INFO:Total runtime is 2.95467408100764 minutes
2022-11-23 11:49:50,800:INFO:SubProcess create_model() called ==================================
2022-11-23 11:49:50,802:INFO:Initializing create_model()
2022-11-23 11:49:50,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:49:50,803:INFO:Checking exceptions
2022-11-23 11:49:50,916:INFO:Importing libraries
2022-11-23 11:49:50,916:INFO:Copying training dataset
2022-11-23 11:49:51,000:INFO:Defining folds
2022-11-23 11:49:51,001:INFO:Declaring metric variables
2022-11-23 11:49:51,148:INFO:Importing untrained model
2022-11-23 11:49:51,237:INFO:K Neighbors Regressor Imported successfully
2022-11-23 11:49:51,373:INFO:Starting cross validation
2022-11-23 11:49:51,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:50:00,748:INFO:Calculating mean and std
2022-11-23 11:50:00,762:INFO:Creating metrics dataframe
2022-11-23 11:50:00,782:INFO:Uploading results into container
2022-11-23 11:50:00,784:INFO:Uploading model into container now
2022-11-23 11:50:00,785:INFO:master_model_container: 11
2022-11-23 11:50:00,786:INFO:display_container: 2
2022-11-23 11:50:00,787:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-23 11:50:00,787:INFO:create_model() successfully completed......................................
2022-11-23 11:50:03,198:INFO:SubProcess create_model() end ==================================
2022-11-23 11:50:03,199:INFO:Creating metrics dataframe
2022-11-23 11:50:03,494:INFO:Initializing Decision Tree Regressor
2022-11-23 11:50:03,495:INFO:Total runtime is 3.166847097873688 minutes
2022-11-23 11:50:03,521:INFO:SubProcess create_model() called ==================================
2022-11-23 11:50:03,521:INFO:Initializing create_model()
2022-11-23 11:50:03,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:50:03,522:INFO:Checking exceptions
2022-11-23 11:50:03,621:INFO:Importing libraries
2022-11-23 11:50:03,622:INFO:Copying training dataset
2022-11-23 11:50:03,679:INFO:Defining folds
2022-11-23 11:50:03,680:INFO:Declaring metric variables
2022-11-23 11:50:03,736:INFO:Importing untrained model
2022-11-23 11:50:03,779:INFO:Decision Tree Regressor Imported successfully
2022-11-23 11:50:03,923:INFO:Starting cross validation
2022-11-23 11:50:03,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:50:08,634:INFO:Calculating mean and std
2022-11-23 11:50:08,640:INFO:Creating metrics dataframe
2022-11-23 11:50:08,655:INFO:Uploading results into container
2022-11-23 11:50:08,658:INFO:Uploading model into container now
2022-11-23 11:50:08,659:INFO:master_model_container: 12
2022-11-23 11:50:08,660:INFO:display_container: 2
2022-11-23 11:50:08,661:INFO:DecisionTreeRegressor(random_state=3936)
2022-11-23 11:50:08,661:INFO:create_model() successfully completed......................................
2022-11-23 11:50:10,130:INFO:SubProcess create_model() end ==================================
2022-11-23 11:50:10,131:INFO:Creating metrics dataframe
2022-11-23 11:50:10,280:INFO:Initializing Random Forest Regressor
2022-11-23 11:50:10,281:INFO:Total runtime is 3.2799571394920353 minutes
2022-11-23 11:50:10,298:INFO:SubProcess create_model() called ==================================
2022-11-23 11:50:10,300:INFO:Initializing create_model()
2022-11-23 11:50:10,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:50:10,300:INFO:Checking exceptions
2022-11-23 11:50:10,305:INFO:Importing libraries
2022-11-23 11:50:10,305:INFO:Copying training dataset
2022-11-23 11:50:10,384:INFO:Defining folds
2022-11-23 11:50:10,384:INFO:Declaring metric variables
2022-11-23 11:50:10,431:INFO:Importing untrained model
2022-11-23 11:50:10,473:INFO:Random Forest Regressor Imported successfully
2022-11-23 11:50:10,595:INFO:Starting cross validation
2022-11-23 11:50:10,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:50:54,516:INFO:Calculating mean and std
2022-11-23 11:50:54,532:INFO:Creating metrics dataframe
2022-11-23 11:50:54,550:INFO:Uploading results into container
2022-11-23 11:50:54,551:INFO:Uploading model into container now
2022-11-23 11:50:54,553:INFO:master_model_container: 13
2022-11-23 11:50:54,556:INFO:display_container: 2
2022-11-23 11:50:54,559:INFO:RandomForestRegressor(n_jobs=-1, random_state=3936)
2022-11-23 11:50:54,559:INFO:create_model() successfully completed......................................
2022-11-23 11:50:55,503:INFO:SubProcess create_model() end ==================================
2022-11-23 11:50:55,513:INFO:Creating metrics dataframe
2022-11-23 11:50:55,627:INFO:Initializing Extra Trees Regressor
2022-11-23 11:50:55,632:INFO:Total runtime is 4.035808126131694 minutes
2022-11-23 11:50:55,653:INFO:SubProcess create_model() called ==================================
2022-11-23 11:50:55,660:INFO:Initializing create_model()
2022-11-23 11:50:55,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:50:55,662:INFO:Checking exceptions
2022-11-23 11:50:55,681:INFO:Importing libraries
2022-11-23 11:50:55,682:INFO:Copying training dataset
2022-11-23 11:50:55,720:INFO:Defining folds
2022-11-23 11:50:55,725:INFO:Declaring metric variables
2022-11-23 11:50:55,747:INFO:Importing untrained model
2022-11-23 11:50:55,773:INFO:Extra Trees Regressor Imported successfully
2022-11-23 11:50:55,816:INFO:Starting cross validation
2022-11-23 11:50:55,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:51:33,409:INFO:Calculating mean and std
2022-11-23 11:51:33,424:INFO:Creating metrics dataframe
2022-11-23 11:51:33,446:INFO:Uploading results into container
2022-11-23 11:51:33,448:INFO:Uploading model into container now
2022-11-23 11:51:33,449:INFO:master_model_container: 14
2022-11-23 11:51:33,450:INFO:display_container: 2
2022-11-23 11:51:33,468:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3936)
2022-11-23 11:51:33,473:INFO:create_model() successfully completed......................................
2022-11-23 11:51:35,025:INFO:SubProcess create_model() end ==================================
2022-11-23 11:51:35,026:INFO:Creating metrics dataframe
2022-11-23 11:51:35,210:INFO:Initializing AdaBoost Regressor
2022-11-23 11:51:35,210:INFO:Total runtime is 4.695450981458029 minutes
2022-11-23 11:51:35,250:INFO:SubProcess create_model() called ==================================
2022-11-23 11:51:35,254:INFO:Initializing create_model()
2022-11-23 11:51:35,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:51:35,257:INFO:Checking exceptions
2022-11-23 11:51:35,264:INFO:Importing libraries
2022-11-23 11:51:35,264:INFO:Copying training dataset
2022-11-23 11:51:35,320:INFO:Defining folds
2022-11-23 11:51:35,322:INFO:Declaring metric variables
2022-11-23 11:51:35,490:INFO:Importing untrained model
2022-11-23 11:51:35,533:INFO:AdaBoost Regressor Imported successfully
2022-11-23 11:51:35,849:INFO:Starting cross validation
2022-11-23 11:51:35,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:51:47,430:INFO:Calculating mean and std
2022-11-23 11:51:47,444:INFO:Creating metrics dataframe
2022-11-23 11:51:47,473:INFO:Uploading results into container
2022-11-23 11:51:47,477:INFO:Uploading model into container now
2022-11-23 11:51:47,479:INFO:master_model_container: 15
2022-11-23 11:51:47,480:INFO:display_container: 2
2022-11-23 11:51:47,481:INFO:AdaBoostRegressor(random_state=3936)
2022-11-23 11:51:47,481:INFO:create_model() successfully completed......................................
2022-11-23 11:51:48,383:INFO:SubProcess create_model() end ==================================
2022-11-23 11:51:48,384:INFO:Creating metrics dataframe
2022-11-23 11:51:48,478:INFO:Initializing Gradient Boosting Regressor
2022-11-23 11:51:48,478:INFO:Total runtime is 4.916578849156698 minutes
2022-11-23 11:51:48,520:INFO:SubProcess create_model() called ==================================
2022-11-23 11:51:48,521:INFO:Initializing create_model()
2022-11-23 11:51:48,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:51:48,522:INFO:Checking exceptions
2022-11-23 11:51:48,530:INFO:Importing libraries
2022-11-23 11:51:48,530:INFO:Copying training dataset
2022-11-23 11:51:48,599:INFO:Defining folds
2022-11-23 11:51:48,600:INFO:Declaring metric variables
2022-11-23 11:51:48,630:INFO:Importing untrained model
2022-11-23 11:51:48,660:INFO:Gradient Boosting Regressor Imported successfully
2022-11-23 11:51:48,733:INFO:Starting cross validation
2022-11-23 11:51:48,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:52:03,812:INFO:Calculating mean and std
2022-11-23 11:52:03,823:INFO:Creating metrics dataframe
2022-11-23 11:52:03,845:INFO:Uploading results into container
2022-11-23 11:52:03,846:INFO:Uploading model into container now
2022-11-23 11:52:03,849:INFO:master_model_container: 16
2022-11-23 11:52:03,849:INFO:display_container: 2
2022-11-23 11:52:03,854:INFO:GradientBoostingRegressor(random_state=3936)
2022-11-23 11:52:03,854:INFO:create_model() successfully completed......................................
2022-11-23 11:52:04,763:INFO:SubProcess create_model() end ==================================
2022-11-23 11:52:04,764:INFO:Creating metrics dataframe
2022-11-23 11:52:04,860:INFO:Initializing Extreme Gradient Boosting
2022-11-23 11:52:04,861:INFO:Total runtime is 5.189632944266002 minutes
2022-11-23 11:52:04,907:INFO:SubProcess create_model() called ==================================
2022-11-23 11:52:04,908:INFO:Initializing create_model()
2022-11-23 11:52:04,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:52:04,908:INFO:Checking exceptions
2022-11-23 11:52:04,918:INFO:Importing libraries
2022-11-23 11:52:04,918:INFO:Copying training dataset
2022-11-23 11:52:04,953:INFO:Defining folds
2022-11-23 11:52:04,955:INFO:Declaring metric variables
2022-11-23 11:52:04,978:INFO:Importing untrained model
2022-11-23 11:52:05,012:INFO:Extreme Gradient Boosting Imported successfully
2022-11-23 11:52:05,059:INFO:Starting cross validation
2022-11-23 11:52:05,064:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:52:18,112:INFO:Calculating mean and std
2022-11-23 11:52:18,126:INFO:Creating metrics dataframe
2022-11-23 11:52:18,154:INFO:Uploading results into container
2022-11-23 11:52:18,156:INFO:Uploading model into container now
2022-11-23 11:52:18,158:INFO:master_model_container: 17
2022-11-23 11:52:18,159:INFO:display_container: 2
2022-11-23 11:52:18,163:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=3936, ...)
2022-11-23 11:52:18,164:INFO:create_model() successfully completed......................................
2022-11-23 11:52:19,040:INFO:SubProcess create_model() end ==================================
2022-11-23 11:52:19,041:INFO:Creating metrics dataframe
2022-11-23 11:52:19,130:INFO:Initializing Light Gradient Boosting Machine
2022-11-23 11:52:19,130:INFO:Total runtime is 5.427452266216279 minutes
2022-11-23 11:52:19,149:INFO:SubProcess create_model() called ==================================
2022-11-23 11:52:19,157:INFO:Initializing create_model()
2022-11-23 11:52:19,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:52:19,158:INFO:Checking exceptions
2022-11-23 11:52:19,175:INFO:Importing libraries
2022-11-23 11:52:19,176:INFO:Copying training dataset
2022-11-23 11:52:19,195:INFO:Defining folds
2022-11-23 11:52:19,197:INFO:Declaring metric variables
2022-11-23 11:52:19,229:INFO:Importing untrained model
2022-11-23 11:52:19,256:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-23 11:52:19,320:INFO:Starting cross validation
2022-11-23 11:52:19,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:52:25,688:INFO:Calculating mean and std
2022-11-23 11:52:25,695:INFO:Creating metrics dataframe
2022-11-23 11:52:25,725:INFO:Uploading results into container
2022-11-23 11:52:25,730:INFO:Uploading model into container now
2022-11-23 11:52:25,731:INFO:master_model_container: 18
2022-11-23 11:52:25,731:INFO:display_container: 2
2022-11-23 11:52:25,738:INFO:LGBMRegressor(random_state=3936)
2022-11-23 11:52:25,738:INFO:create_model() successfully completed......................................
2022-11-23 11:52:26,596:INFO:SubProcess create_model() end ==================================
2022-11-23 11:52:26,597:INFO:Creating metrics dataframe
2022-11-23 11:52:26,693:INFO:Initializing Dummy Regressor
2022-11-23 11:52:26,693:INFO:Total runtime is 5.553502595424653 minutes
2022-11-23 11:52:26,713:INFO:SubProcess create_model() called ==================================
2022-11-23 11:52:26,714:INFO:Initializing create_model()
2022-11-23 11:52:26,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C3F11AE0>, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:52:26,717:INFO:Checking exceptions
2022-11-23 11:52:26,741:INFO:Importing libraries
2022-11-23 11:52:26,743:INFO:Copying training dataset
2022-11-23 11:52:26,764:INFO:Defining folds
2022-11-23 11:52:26,773:INFO:Declaring metric variables
2022-11-23 11:52:26,797:INFO:Importing untrained model
2022-11-23 11:52:26,822:INFO:Dummy Regressor Imported successfully
2022-11-23 11:52:26,907:INFO:Starting cross validation
2022-11-23 11:52:26,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:52:28,009:INFO:Calculating mean and std
2022-11-23 11:52:28,020:INFO:Creating metrics dataframe
2022-11-23 11:52:28,040:INFO:Uploading results into container
2022-11-23 11:52:28,043:INFO:Uploading model into container now
2022-11-23 11:52:28,045:INFO:master_model_container: 19
2022-11-23 11:52:28,045:INFO:display_container: 2
2022-11-23 11:52:28,050:INFO:DummyRegressor()
2022-11-23 11:52:28,051:INFO:create_model() successfully completed......................................
2022-11-23 11:52:29,494:INFO:SubProcess create_model() end ==================================
2022-11-23 11:52:29,496:INFO:Creating metrics dataframe
2022-11-23 11:52:29,706:INFO:Initializing create_model()
2022-11-23 11:52:29,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=LGBMRegressor(random_state=3936), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:52:29,712:INFO:Checking exceptions
2022-11-23 11:52:29,725:INFO:Importing libraries
2022-11-23 11:52:29,726:INFO:Copying training dataset
2022-11-23 11:52:29,746:INFO:Defining folds
2022-11-23 11:52:29,746:INFO:Declaring metric variables
2022-11-23 11:52:29,747:INFO:Importing untrained model
2022-11-23 11:52:29,747:INFO:Declaring custom model
2022-11-23 11:52:29,762:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-23 11:52:29,764:INFO:Cross validation set to False
2022-11-23 11:52:29,765:INFO:Fitting Model
2022-11-23 11:52:31,060:INFO:LGBMRegressor(random_state=3936)
2022-11-23 11:52:31,061:INFO:create_model() successfully completed......................................
2022-11-23 11:52:32,691:INFO:master_model_container: 19
2022-11-23 11:52:32,692:INFO:display_container: 2
2022-11-23 11:52:32,693:INFO:LGBMRegressor(random_state=3936)
2022-11-23 11:52:32,693:INFO:compare_models() successfully completed......................................
2022-11-23 11:52:32,803:INFO:Initializing create_model()
2022-11-23 11:52:32,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:52:32,804:INFO:Checking exceptions
2022-11-23 11:52:33,129:INFO:Importing libraries
2022-11-23 11:52:33,129:INFO:Copying training dataset
2022-11-23 11:52:33,158:INFO:Defining folds
2022-11-23 11:52:33,159:INFO:Declaring metric variables
2022-11-23 11:52:33,224:INFO:Importing untrained model
2022-11-23 11:52:33,262:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-23 11:52:33,408:INFO:Starting cross validation
2022-11-23 11:52:33,411:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:52:39,906:INFO:Calculating mean and std
2022-11-23 11:52:39,925:INFO:Creating metrics dataframe
2022-11-23 11:52:40,006:INFO:Finalizing model
2022-11-23 11:52:49,913:INFO:Uploading results into container
2022-11-23 11:52:49,920:INFO:Uploading model into container now
2022-11-23 11:52:50,005:INFO:master_model_container: 20
2022-11-23 11:52:50,005:INFO:display_container: 3
2022-11-23 11:52:50,006:INFO:LGBMRegressor(random_state=3936)
2022-11-23 11:52:50,006:INFO:create_model() successfully completed......................................
2022-11-23 11:52:52,095:INFO:Initializing plot_model()
2022-11-23 11:52:52,096:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3936), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, system=True)
2022-11-23 11:52:52,096:INFO:Checking exceptions
2022-11-23 11:52:52,129:INFO:Preloading libraries
2022-11-23 11:52:52,225:INFO:Copying training dataset
2022-11-23 11:52:52,225:INFO:Plot type: feature
2022-11-23 11:52:52,226:WARNING:No coef_ found. Trying feature_importances_
2022-11-23 11:52:56,680:INFO:Visual Rendered Successfully
2022-11-23 11:52:58,957:INFO:plot_model() successfully completed......................................
2022-11-23 11:52:59,293:INFO:Initializing tune_model()
2022-11-23 11:52:59,294:INFO:tune_model(estimator=LGBMRegressor(random_state=3936), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>)
2022-11-23 11:52:59,294:INFO:Checking exceptions
2022-11-23 11:52:59,604:INFO:Copying training dataset
2022-11-23 11:52:59,663:INFO:Checking base model
2022-11-23 11:52:59,673:INFO:Base model : Light Gradient Boosting Machine
2022-11-23 11:52:59,695:INFO:Declaring metric variables
2022-11-23 11:52:59,763:INFO:Defining Hyperparameters
2022-11-23 11:53:01,926:INFO:Tuning with n_jobs=-1
2022-11-23 11:53:01,927:INFO:Initializing RandomizedSearchCV
2022-11-23 11:54:07,855:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.6}
2022-11-23 11:54:07,883:INFO:Hyperparameter search completed
2022-11-23 11:54:07,883:INFO:SubProcess create_model() called ==================================
2022-11-23 11:54:07,885:INFO:Initializing create_model()
2022-11-23 11:54:07,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=LGBMRegressor(random_state=3936), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000297C4A60C40>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 4, 'reg_alpha': 2, 'num_leaves': 10, 'n_estimators': 280, 'min_split_gain': 0.1, 'min_child_samples': 61, 'learning_rate': 0.3, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.6})
2022-11-23 11:54:07,885:INFO:Checking exceptions
2022-11-23 11:54:07,898:INFO:Importing libraries
2022-11-23 11:54:07,898:INFO:Copying training dataset
2022-11-23 11:54:07,918:INFO:Defining folds
2022-11-23 11:54:07,918:INFO:Declaring metric variables
2022-11-23 11:54:07,976:INFO:Importing untrained model
2022-11-23 11:54:07,980:INFO:Declaring custom model
2022-11-23 11:54:08,035:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-23 11:54:08,175:INFO:Starting cross validation
2022-11-23 11:54:08,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:54:15,288:INFO:Calculating mean and std
2022-11-23 11:54:15,290:INFO:Creating metrics dataframe
2022-11-23 11:54:15,347:INFO:Finalizing model
2022-11-23 11:54:18,722:INFO:Uploading results into container
2022-11-23 11:54:18,724:INFO:Uploading model into container now
2022-11-23 11:54:18,735:INFO:master_model_container: 21
2022-11-23 11:54:18,736:INFO:display_container: 4
2022-11-23 11:54:18,756:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.8,
              learning_rate=0.3, min_child_samples=61, min_split_gain=0.1,
              n_estimators=280, num_leaves=10, random_state=3936, reg_alpha=2,
              reg_lambda=4)
2022-11-23 11:54:18,757:INFO:create_model() successfully completed......................................
2022-11-23 11:54:20,820:INFO:SubProcess create_model() end ==================================
2022-11-23 11:54:20,821:INFO:choose_better activated
2022-11-23 11:54:20,855:INFO:SubProcess create_model() called ==================================
2022-11-23 11:54:20,858:INFO:Initializing create_model()
2022-11-23 11:54:20,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, estimator=LGBMRegressor(random_state=3936), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-23 11:54:20,873:INFO:Checking exceptions
2022-11-23 11:54:20,940:INFO:Importing libraries
2022-11-23 11:54:20,941:INFO:Copying training dataset
2022-11-23 11:54:20,972:INFO:Defining folds
2022-11-23 11:54:20,973:INFO:Declaring metric variables
2022-11-23 11:54:20,973:INFO:Importing untrained model
2022-11-23 11:54:20,974:INFO:Declaring custom model
2022-11-23 11:54:20,990:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-23 11:54:21,000:INFO:Starting cross validation
2022-11-23 11:54:21,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-23 11:54:27,706:INFO:Calculating mean and std
2022-11-23 11:54:27,707:INFO:Creating metrics dataframe
2022-11-23 11:54:27,723:INFO:Finalizing model
2022-11-23 11:54:28,835:INFO:Uploading results into container
2022-11-23 11:54:28,837:INFO:Uploading model into container now
2022-11-23 11:54:28,838:INFO:master_model_container: 22
2022-11-23 11:54:28,838:INFO:display_container: 5
2022-11-23 11:54:28,839:INFO:LGBMRegressor(random_state=3936)
2022-11-23 11:54:28,839:INFO:create_model() successfully completed......................................
2022-11-23 11:54:30,389:INFO:SubProcess create_model() end ==================================
2022-11-23 11:54:30,398:INFO:LGBMRegressor(random_state=3936) result for R2 is 0.8601
2022-11-23 11:54:30,403:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.8,
              learning_rate=0.3, min_child_samples=61, min_split_gain=0.1,
              n_estimators=280, num_leaves=10, random_state=3936, reg_alpha=2,
              reg_lambda=4) result for R2 is 0.851
2022-11-23 11:54:30,404:INFO:LGBMRegressor(random_state=3936) is best model
2022-11-23 11:54:30,404:INFO:choose_better completed
2022-11-23 11:54:30,405:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-11-23 11:54:30,669:INFO:master_model_container: 22
2022-11-23 11:54:30,669:INFO:display_container: 4
2022-11-23 11:54:30,673:INFO:LGBMRegressor(random_state=3936)
2022-11-23 11:54:30,673:INFO:tune_model() successfully completed......................................
2022-11-23 11:54:33,607:INFO:Initializing plot_model()
2022-11-23 11:54:33,607:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=3936), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000297C3F11E40>, system=True)
2022-11-23 11:54:33,613:INFO:Checking exceptions
2022-11-23 11:54:33,635:INFO:Preloading libraries
2022-11-23 11:54:33,734:INFO:Copying training dataset
2022-11-23 11:54:33,734:INFO:Plot type: residuals
2022-11-23 11:54:35,154:INFO:Fitting Model
2022-11-23 11:54:36,524:INFO:Scoring test/hold-out set
2022-11-23 11:54:46,104:INFO:Visual Rendered Successfully
2022-11-23 11:54:48,615:INFO:plot_model() successfully completed......................................
2022-11-23 11:54:48,902:INFO:Initializing save_model()
2022-11-23 11:54:48,902:INFO:save_model(model=LGBMRegressor(random_state=3936), model_name=Coches_gbr, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\nacho\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-11-23 11:54:48,902:INFO:Adding model into prep_pipe
2022-11-23 11:54:48,960:INFO:Coches_gbr.pkl saved in current working directory
2022-11-23 11:54:49,105:INFO:Pipeline(memory=Memory(location=C:\Users\nacho\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model', LGBMRegressor(random_state=3936))])
2022-11-23 11:54:49,105:INFO:save_model() successfully completed......................................
